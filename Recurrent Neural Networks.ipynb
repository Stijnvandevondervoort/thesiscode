{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timeit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bResult</th>\n",
       "      <th>rResult</th>\n",
       "      <th>game_id</th>\n",
       "      <th>minute</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Type</th>\n",
       "      <th>blueTeamTag</th>\n",
       "      <th>redTeamTag</th>\n",
       "      <th>...</th>\n",
       "      <th>killsredTop</th>\n",
       "      <th>killsredJungle</th>\n",
       "      <th>killsredMiddle</th>\n",
       "      <th>killsredADC</th>\n",
       "      <th>killsredSupport</th>\n",
       "      <th>killsblueTop</th>\n",
       "      <th>killsblueJungle</th>\n",
       "      <th>killsblueMiddle</th>\n",
       "      <th>killsblueADC</th>\n",
       "      <th>killsblueSupport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NALCS</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Season</td>\n",
       "      <td>TSM</td>\n",
       "      <td>C9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NALCS</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Season</td>\n",
       "      <td>TSM</td>\n",
       "      <td>C9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NALCS</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Season</td>\n",
       "      <td>TSM</td>\n",
       "      <td>C9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NALCS</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Season</td>\n",
       "      <td>TSM</td>\n",
       "      <td>C9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NALCS</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Season</td>\n",
       "      <td>TSM</td>\n",
       "      <td>C9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bResult  rResult  game_id  minute League  Year  Season    Type blueTeamTag  \\\n",
       "0        1        0        0       1  NALCS  2015  Spring  Season         TSM   \n",
       "1        1        0        0       2  NALCS  2015  Spring  Season         TSM   \n",
       "2        1        0        0       3  NALCS  2015  Spring  Season         TSM   \n",
       "3        1        0        0       4  NALCS  2015  Spring  Season         TSM   \n",
       "4        1        0        0       5  NALCS  2015  Spring  Season         TSM   \n",
       "\n",
       "  redTeamTag        ...         killsredTop  killsredJungle  killsredMiddle  \\\n",
       "0         C9        ...                   0               0               0   \n",
       "1         C9        ...                   0               0               0   \n",
       "2         C9        ...                   0               0               0   \n",
       "3         C9        ...                   0               0               0   \n",
       "4         C9        ...                   0               0               0   \n",
       "\n",
       "   killsredADC  killsredSupport  killsblueTop  killsblueJungle  \\\n",
       "0            0                0             0                0   \n",
       "1            0                0             0                0   \n",
       "2            0                0             0                0   \n",
       "3            0                0             0                0   \n",
       "4            0                0             0                0   \n",
       "\n",
       "   killsblueMiddle  killsblueADC  killsblueSupport  \n",
       "0                0             0                 0  \n",
       "1                0             0                 0  \n",
       "2                0             0                 0  \n",
       "3                0             0                 0  \n",
       "4                0             0                 0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data.xlsx', index_col=0) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only nummeric features\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df = df.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train en test\n",
    "unique_game_id = df.game_id.unique()\n",
    "train_game_id , test_game_id= train_test_split(unique_game_id,test_size=0.30, random_state=42)\n",
    "\n",
    "test_data = df[df.game_id.isin(test_game_id)]\n",
    "train_data = df[df.game_id.isin(train_game_id)]\n",
    "xtest = test_data.drop(\"bResult\",axis=1)\n",
    "xtest = xtest.drop(\"rResult\",axis=1)\n",
    "ytest = test_data.bResult\n",
    "xtrain = train_data.drop(\"bResult\",axis=1)\n",
    "xtrain = xtrain.drop(\"rResult\",axis=1)\n",
    "ytrain = train_data.bResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest5 = test_data.bResult[test_data.minute<6]\n",
    "ytest10 = test_data.bResult[test_data.minute<11][test_data.minute>5]\n",
    "ytest15 = test_data.bResult[test_data.minute<16][test_data.minute>10]\n",
    "ytest20 = test_data.bResult[test_data.minute<21][test_data.minute>15]\n",
    "ytest25 = test_data.bResult[test_data.minute<26][test_data.minute>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.3121473  seconds\n"
     ]
    }
   ],
   "source": [
    "#get train data in right shape with timestep 9\n",
    "start = timeit.default_timer()\n",
    "listie = []\n",
    "zeropadlist = np.zeros((1,len(xtrain.columns)))\n",
    "for i in range(len(xtrain)):\n",
    "    temp = []\n",
    "    if xtrain.minute.iloc[i]>8:\n",
    "        for j in range(9):\n",
    "            temp.append((xtrain.iloc[i-8+j].values))\n",
    "        \n",
    "    elif xtrain.minute.iloc[i] ==1:\n",
    "        for j in range(8):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        temp.append((xtrain.iloc[i].values))\n",
    "        \n",
    "    elif xtrain.minute.iloc[i] ==2:\n",
    "        for j in range(7):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(2):\n",
    "            temp.append((xtrain.iloc[i-1+j].values))\n",
    "            \n",
    "    elif xtrain.minute.iloc[i] ==3:\n",
    "        for j in range(6):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(3):\n",
    "            temp.append((xtrain.iloc[i-2+j].values))\n",
    "                        \n",
    "    elif xtrain.minute.iloc[i] ==4:\n",
    "        for j in range(5):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(4):\n",
    "            temp.append((xtrain.iloc[i-3+j].values))\n",
    "                        \n",
    "    elif xtrain.minute.iloc[i] ==5:\n",
    "        for j in range(4):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(5):\n",
    "            temp.append((xtrain.iloc[i-4+j].values))\n",
    "                        \n",
    "    elif xtrain.minute.iloc[i] ==6:\n",
    "        for j in range(3):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(6):\n",
    "            temp.append((xtrain.iloc[i-5+j].values))\n",
    "\n",
    "    elif xtrain.minute.iloc[i] ==7:\n",
    "        for j in range(2):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(7):\n",
    "            temp.append((xtrain.iloc[i-6+j].values))\n",
    "                        \n",
    "    elif xtrain.minute.iloc[i] ==8:\n",
    "        for j in range(1):\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(8):\n",
    "            temp.append((xtrain.iloc[i-7+j].values))\n",
    "                        \n",
    "\n",
    "    listie.append((temp))\n",
    "elapsed = timeit.default_timer() - start\n",
    "print(elapsed, \" seconds\")\n",
    "xtrain = np.array(listie)\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[1], xtrain.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.64647750000006  seconds\n"
     ]
    }
   ],
   "source": [
    "#get test data in right shape with timestep 9\n",
    "start = timeit.default_timer()\n",
    "listie = []\n",
    "listie5 = []\n",
    "listie10 = []\n",
    "listie15 = []\n",
    "listie20 = []\n",
    "listie25 = []\n",
    "zeropadlist = np.zeros((1,len(xtest.columns)))\n",
    "for i in range(len(xtest)):\n",
    "    temp = []\n",
    "    temp5 = []\n",
    "    temp10 = []\n",
    "    temp15 = []\n",
    "    temp20 = []\n",
    "    temp25 = []\n",
    "    if xtest.minute.iloc[i]>8:\n",
    "        if xtest.minute.iloc[i]<11:\n",
    "            for j in range(9):\n",
    "                temp10.append((xtest.iloc[i-8+j].values))\n",
    "        elif xtest.minute.iloc[i]<16:\n",
    "            for j in range(9):\n",
    "                temp15.append((xtest.iloc[i-8+j].values))\n",
    "        elif xtest.minute.iloc[i]<21:\n",
    "            for j in range(9):\n",
    "                temp20.append((xtest.iloc[i-8+j].values))\n",
    "        elif xtest.minute.iloc[i]<26:\n",
    "            for j in range(9):\n",
    "                temp25.append((xtest.iloc[i-8+j].values))\n",
    "\n",
    "        for j in range(9):\n",
    "            temp.append((xtest.iloc[i-8+j].values))\n",
    "        \n",
    "    elif xtest.minute.iloc[i] ==1:\n",
    "        for j in range(8):\n",
    "            temp5.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        temp5.append((xtest.iloc[i].values)) \n",
    "        temp.append((xtest.iloc[i].values))\n",
    "\n",
    "    elif xtest.minute.iloc[i] ==2:\n",
    "        for j in range(7):\n",
    "            temp5.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(2):\n",
    "            temp5.append((xtest.iloc[i-1+j].values))\n",
    "            temp.append((xtest.iloc[i-1+j].values))\n",
    "            \n",
    "    elif xtest.minute.iloc[i] ==3:\n",
    "        for j in range(6):\n",
    "            temp5.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(3):\n",
    "            temp5.append((xtest.iloc[i-2+j].values))\n",
    "            temp.append((xtest.iloc[i-2+j].values))\n",
    "                        \n",
    "    elif xtest.minute.iloc[i] ==4:\n",
    "        for j in range(5):\n",
    "            temp5.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(4):\n",
    "            temp5.append((xtest.iloc[i-3+j].values))\n",
    "            temp.append((xtest.iloc[i-3+j].values))\n",
    "                        \n",
    "    elif xtest.minute.iloc[i] ==5:\n",
    "        for j in range(4):\n",
    "            temp5.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(5):\n",
    "            temp5.append((xtest.iloc[i-4+j].values))\n",
    "            temp.append((xtest.iloc[i-4+j].values))\n",
    "                        \n",
    "    elif xtest.minute.iloc[i] ==6:\n",
    "        for j in range(3):\n",
    "            temp10.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(6):\n",
    "            temp10.append((xtest.iloc[i-5+j].values))\n",
    "            temp.append((xtest.iloc[i-5+j].values))\n",
    "\n",
    "    elif xtest.minute.iloc[i] ==7:\n",
    "        for j in range(2):\n",
    "            temp10.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(7):\n",
    "            temp10.append((xtest.iloc[i-6+j].values))\n",
    "            temp.append((xtest.iloc[i-6+j].values))\n",
    "                        \n",
    "    elif xtest.minute.iloc[i] ==8:\n",
    "        for j in range(1):\n",
    "            temp10.append((zeropadlist[0]))\n",
    "            temp.append((zeropadlist[0]))\n",
    "        for j in range(8):\n",
    "            temp10.append((xtest.iloc[i-7+j].values))\n",
    "            temp.append((xtest.iloc[i-7+j].values))\n",
    "            \n",
    "    listie.append((temp))\n",
    "    if xtest.minute.iloc[i]<6:\n",
    "        listie5.append((temp5))\n",
    "    elif xtest.minute.iloc[i]<11:    \n",
    "        listie10.append((temp10))\n",
    "    elif xtest.minute.iloc[i]<16:    \n",
    "        listie15.append((temp15))\n",
    "    elif xtest.minute.iloc[i]<21:    \n",
    "        listie20.append((temp20))\n",
    "    elif xtest.minute.iloc[i]<26:    \n",
    "        listie25.append((temp25))\n",
    "    \n",
    "elapsed = timeit.default_timer() - start\n",
    "print(elapsed, \" seconds\")\n",
    "\n",
    "\n",
    "listie = np.array(listie)\n",
    "xtest = np.reshape(listie, (listie.shape[0], listie.shape[1], listie.shape[2]))\n",
    "listie5 = np.array(listie5)\n",
    "xtest5 = np.reshape(listie5, (listie5.shape[0], listie5.shape[1], listie5.shape[2]))\n",
    "listie10 = np.array(listie10)\n",
    "xtest10 = np.reshape(listie10, (listie10.shape[0], listie10.shape[1], listie10.shape[2]))\n",
    "\n",
    "listie15 = np.array(listie15)\n",
    "xtest15 = np.reshape(listie15, (listie15.shape[0], listie15.shape[1], listie15.shape[2]))\n",
    "listie20 = np.array(listie20)\n",
    "xtest20 = np.reshape(listie20, (listie20.shape[0], listie20.shape[1], listie20.shape[2]))\n",
    "\n",
    "listie25 = np.array(listie25)\n",
    "xtest25 = np.reshape(listie25, (listie25.shape[0], listie25.shape[1], listie25.shape[2])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "import pandas\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 13s - loss: 0.7035 - acc: 0.5231 - val_loss: 0.6919 - val_acc: 0.5365\n",
      "Epoch 2/50\n",
      " - 9s - loss: 0.6838 - acc: 0.5587 - val_loss: 0.6924 - val_acc: 0.5263\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.6859 - acc: 0.5528 - val_loss: 0.6955 - val_acc: 0.5115\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6822 - acc: 0.5585 - val_loss: 0.6931 - val_acc: 0.5003\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.6688 - acc: 0.5819 - val_loss: 0.6956 - val_acc: 0.5508\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6559 - acc: 0.6074 - val_loss: 0.6991 - val_acc: 0.5432\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6426 - acc: 0.6259 - val_loss: 0.6992 - val_acc: 0.5465\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.6292 - acc: 0.6376 - val_loss: 0.6944 - val_acc: 0.5528\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.6199 - acc: 0.6473 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 10/50\n",
      " - 9s - loss: 0.6101 - acc: 0.6470 - val_loss: 0.6880 - val_acc: 0.5516\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.6118 - acc: 0.6547 - val_loss: 0.6861 - val_acc: 0.5539\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.6084 - acc: 0.6565 - val_loss: 0.6928 - val_acc: 0.5296\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.6088 - acc: 0.6525 - val_loss: 0.7143 - val_acc: 0.5345\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.6029 - acc: 0.6526 - val_loss: 0.7120 - val_acc: 0.5542\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6000 - acc: 0.6577 - val_loss: 0.7248 - val_acc: 0.5654\n",
      "Epoch 16/50\n",
      " - 9s - loss: 0.5975 - acc: 0.6642 - val_loss: 0.7082 - val_acc: 0.5590\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.5935 - acc: 0.6672 - val_loss: 0.7083 - val_acc: 0.5683\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.5942 - acc: 0.6683 - val_loss: 0.7002 - val_acc: 0.5659\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.5896 - acc: 0.6672 - val_loss: 0.6976 - val_acc: 0.5701\n",
      "Epoch 20/50\n",
      " - 9s - loss: 0.5879 - acc: 0.6706 - val_loss: 0.6945 - val_acc: 0.5649\n",
      "Epoch 21/50\n",
      " - 8s - loss: 0.5884 - acc: 0.6729 - val_loss: 0.6912 - val_acc: 0.5646\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.5855 - acc: 0.6710 - val_loss: 0.7015 - val_acc: 0.5644\n",
      "Epoch 23/50\n",
      " - 8s - loss: 0.5875 - acc: 0.6692 - val_loss: 0.6844 - val_acc: 0.5612\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5841 - acc: 0.6704 - val_loss: 0.7014 - val_acc: 0.5676\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.5876 - acc: 0.6717 - val_loss: 0.6797 - val_acc: 0.5592\n",
      "Epoch 26/50\n",
      " - 8s - loss: 0.5856 - acc: 0.6714 - val_loss: 0.6949 - val_acc: 0.5653\n",
      "Epoch 27/50\n",
      " - 8s - loss: 0.5872 - acc: 0.6730 - val_loss: 0.6909 - val_acc: 0.5658\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.5862 - acc: 0.6759 - val_loss: 0.6880 - val_acc: 0.5656\n",
      "Epoch 29/50\n",
      " - 8s - loss: 0.5850 - acc: 0.6734 - val_loss: 0.6857 - val_acc: 0.5600\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.5874 - acc: 0.6712 - val_loss: 0.6920 - val_acc: 0.5624\n",
      "Epoch 31/50\n",
      " - 8s - loss: 0.5930 - acc: 0.6726 - val_loss: 0.6845 - val_acc: 0.5681\n",
      "Epoch 32/50\n",
      " - 8s - loss: 0.5911 - acc: 0.6753 - val_loss: 0.6871 - val_acc: 0.5595\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.5931 - acc: 0.6747 - val_loss: 0.6959 - val_acc: 0.5538\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.5919 - acc: 0.6745 - val_loss: 0.7004 - val_acc: 0.5615\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5910 - acc: 0.6749 - val_loss: 0.6996 - val_acc: 0.5644\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.5888 - acc: 0.6723 - val_loss: 0.7019 - val_acc: 0.5626\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.5917 - acc: 0.6742 - val_loss: 0.7096 - val_acc: 0.5531\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.5910 - acc: 0.6721 - val_loss: 0.7300 - val_acc: 0.5585\n",
      "Epoch 39/50\n",
      " - 8s - loss: 0.5925 - acc: 0.6740 - val_loss: 0.7247 - val_acc: 0.5670\n",
      "Epoch 40/50\n",
      " - 8s - loss: 0.5912 - acc: 0.6754 - val_loss: 0.7140 - val_acc: 0.5701\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.5950 - acc: 0.6761 - val_loss: 0.7251 - val_acc: 0.5657\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.5883 - acc: 0.6741 - val_loss: 0.6984 - val_acc: 0.5661\n",
      "Epoch 43/50\n",
      " - 8s - loss: 0.5889 - acc: 0.6738 - val_loss: 0.7102 - val_acc: 0.5655\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.5888 - acc: 0.6724 - val_loss: 0.7031 - val_acc: 0.5418\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.5895 - acc: 0.6724 - val_loss: 0.7263 - val_acc: 0.5675\n",
      "Epoch 46/50\n",
      " - 8s - loss: 0.5924 - acc: 0.6729 - val_loss: 0.7098 - val_acc: 0.5681\n",
      "Epoch 47/50\n",
      " - 8s - loss: 0.5971 - acc: 0.6757 - val_loss: 0.7119 - val_acc: 0.5667\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.5983 - acc: 0.6764 - val_loss: 0.7167 - val_acc: 0.5682\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.5941 - acc: 0.6771 - val_loss: 0.7287 - val_acc: 0.5647\n",
      "Epoch 50/50\n",
      " - 8s - loss: 0.5947 - acc: 0.6770 - val_loss: 0.6985 - val_acc: 0.5651\n",
      "431.7792191999997  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.6980 - acc: 0.5482 - val_loss: 0.6962 - val_acc: 0.4981\n",
      "Epoch 2/50\n",
      " - 9s - loss: 0.6659 - acc: 0.5908 - val_loss: 0.7007 - val_acc: 0.5255\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.6521 - acc: 0.6132 - val_loss: 0.7049 - val_acc: 0.4918\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.6452 - acc: 0.6231 - val_loss: 0.7122 - val_acc: 0.5210\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.6266 - acc: 0.6384 - val_loss: 0.7033 - val_acc: 0.5088\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.6212 - acc: 0.6467 - val_loss: 0.7098 - val_acc: 0.5255\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.6181 - acc: 0.6524 - val_loss: 0.7335 - val_acc: 0.5279\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6119 - acc: 0.6562 - val_loss: 0.7143 - val_acc: 0.5254\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.6056 - acc: 0.6587 - val_loss: 0.7052 - val_acc: 0.4995\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.6048 - acc: 0.6604 - val_loss: 0.7052 - val_acc: 0.5274\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.6035 - acc: 0.6623 - val_loss: 0.6969 - val_acc: 0.5213\n",
      "Epoch 12/50\n",
      " - 8s - loss: 0.5983 - acc: 0.6687 - val_loss: 0.7141 - val_acc: 0.5281\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.6013 - acc: 0.6666 - val_loss: 0.6985 - val_acc: 0.5351\n",
      "Epoch 14/50\n",
      " - 8s - loss: 0.6013 - acc: 0.6686 - val_loss: 0.7201 - val_acc: 0.5400\n",
      "Epoch 15/50\n",
      " - 8s - loss: 0.5982 - acc: 0.6688 - val_loss: 0.7201 - val_acc: 0.5520\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.5934 - acc: 0.6719 - val_loss: 0.7072 - val_acc: 0.5624\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.5894 - acc: 0.6730 - val_loss: 0.7008 - val_acc: 0.5472\n",
      "Epoch 18/50\n",
      " - 8s - loss: 0.5882 - acc: 0.6752 - val_loss: 0.6908 - val_acc: 0.5537\n",
      "Epoch 19/50\n",
      " - 8s - loss: 0.5915 - acc: 0.6748 - val_loss: 0.6976 - val_acc: 0.5589\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.5859 - acc: 0.6757 - val_loss: 0.6905 - val_acc: 0.5558\n",
      "Epoch 21/50\n",
      " - 8s - loss: 0.5847 - acc: 0.6757 - val_loss: 0.6857 - val_acc: 0.5554\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.5875 - acc: 0.6749 - val_loss: 0.6911 - val_acc: 0.5562\n",
      "Epoch 23/50\n",
      " - 8s - loss: 0.5906 - acc: 0.6779 - val_loss: 0.7006 - val_acc: 0.5640\n",
      "Epoch 24/50\n",
      " - 8s - loss: 0.5908 - acc: 0.6781 - val_loss: 0.7047 - val_acc: 0.5628\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.5871 - acc: 0.6800 - val_loss: 0.7101 - val_acc: 0.5596\n",
      "Epoch 26/50\n",
      " - 8s - loss: 0.5899 - acc: 0.6763 - val_loss: 0.7281 - val_acc: 0.5598\n",
      "Epoch 27/50\n",
      " - 8s - loss: 0.5870 - acc: 0.6775 - val_loss: 0.6936 - val_acc: 0.5616\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.5883 - acc: 0.6772 - val_loss: 0.7135 - val_acc: 0.5661\n",
      "Epoch 29/50\n",
      " - 8s - loss: 0.5940 - acc: 0.6773 - val_loss: 0.7236 - val_acc: 0.5637\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.5899 - acc: 0.6707 - val_loss: 0.7072 - val_acc: 0.5619\n",
      "Epoch 31/50\n",
      " - 8s - loss: 0.5857 - acc: 0.6732 - val_loss: 0.6887 - val_acc: 0.5633\n",
      "Epoch 32/50\n",
      " - 8s - loss: 0.5865 - acc: 0.6769 - val_loss: 0.6914 - val_acc: 0.5663\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.5920 - acc: 0.6796 - val_loss: 0.7249 - val_acc: 0.5658\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.5926 - acc: 0.6782 - val_loss: 0.7103 - val_acc: 0.5677\n",
      "Epoch 35/50\n",
      " - 8s - loss: 0.5922 - acc: 0.6787 - val_loss: 0.7009 - val_acc: 0.5717\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.5899 - acc: 0.6777 - val_loss: 0.7009 - val_acc: 0.5669\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.5930 - acc: 0.6767 - val_loss: 0.6964 - val_acc: 0.5667\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.5890 - acc: 0.6803 - val_loss: 0.6966 - val_acc: 0.5644\n",
      "Epoch 39/50\n",
      " - 8s - loss: 0.5950 - acc: 0.6766 - val_loss: 0.7143 - val_acc: 0.5653\n",
      "Epoch 40/50\n",
      " - 8s - loss: 0.5981 - acc: 0.6772 - val_loss: 0.7209 - val_acc: 0.5682\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.5914 - acc: 0.6759 - val_loss: 0.7237 - val_acc: 0.5695\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.5924 - acc: 0.6768 - val_loss: 0.7011 - val_acc: 0.5688\n",
      "Epoch 43/50\n",
      " - 8s - loss: 0.5937 - acc: 0.6766 - val_loss: 0.6885 - val_acc: 0.5671\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.5979 - acc: 0.6783 - val_loss: 0.7240 - val_acc: 0.5648\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.5938 - acc: 0.6797 - val_loss: 0.7142 - val_acc: 0.5645\n",
      "Epoch 46/50\n",
      " - 8s - loss: 0.5943 - acc: 0.6794 - val_loss: 0.7418 - val_acc: 0.5679\n",
      "Epoch 47/50\n",
      " - 8s - loss: 0.5937 - acc: 0.6791 - val_loss: 0.6956 - val_acc: 0.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      " - 8s - loss: 0.5918 - acc: 0.6776 - val_loss: 0.6912 - val_acc: 0.5682\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.5870 - acc: 0.6789 - val_loss: 0.7038 - val_acc: 0.5688\n",
      "Epoch 50/50\n",
      " - 8s - loss: 0.5887 - acc: 0.6777 - val_loss: 0.7187 - val_acc: 0.5715\n",
      "408.0483014000001  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 10s - loss: 0.6859 - acc: 0.5783 - val_loss: 0.6945 - val_acc: 0.5262\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.6552 - acc: 0.6074 - val_loss: 0.6990 - val_acc: 0.5169\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.6440 - acc: 0.6226 - val_loss: 0.6977 - val_acc: 0.5433\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.6394 - acc: 0.6337 - val_loss: 0.7021 - val_acc: 0.5416\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.6277 - acc: 0.6414 - val_loss: 0.7032 - val_acc: 0.5321\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.6133 - acc: 0.6522 - val_loss: 0.6978 - val_acc: 0.5231\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.6104 - acc: 0.6553 - val_loss: 0.7063 - val_acc: 0.5260\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6004 - acc: 0.6621 - val_loss: 0.7193 - val_acc: 0.5369\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.5983 - acc: 0.6647 - val_loss: 0.7068 - val_acc: 0.5314\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.5970 - acc: 0.6662 - val_loss: 0.7046 - val_acc: 0.5350\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.5974 - acc: 0.6673 - val_loss: 0.6972 - val_acc: 0.5500\n",
      "Epoch 12/50\n",
      " - 8s - loss: 0.5996 - acc: 0.6668 - val_loss: 0.7025 - val_acc: 0.5480\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.5945 - acc: 0.6675 - val_loss: 0.6969 - val_acc: 0.5542\n",
      "Epoch 14/50\n",
      " - 8s - loss: 0.5914 - acc: 0.6713 - val_loss: 0.7066 - val_acc: 0.5415\n",
      "Epoch 15/50\n",
      " - 8s - loss: 0.5965 - acc: 0.6681 - val_loss: 0.7168 - val_acc: 0.5614\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.5929 - acc: 0.6686 - val_loss: 0.6992 - val_acc: 0.5484\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.5928 - acc: 0.6698 - val_loss: 0.7151 - val_acc: 0.5621\n",
      "Epoch 18/50\n",
      " - 8s - loss: 0.5938 - acc: 0.6746 - val_loss: 0.6959 - val_acc: 0.5681\n",
      "Epoch 19/50\n",
      " - 8s - loss: 0.5934 - acc: 0.6730 - val_loss: 0.7006 - val_acc: 0.5657\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.5931 - acc: 0.6742 - val_loss: 0.7127 - val_acc: 0.5587\n",
      "Epoch 21/50\n",
      " - 12398s - loss: 0.5943 - acc: 0.6717 - val_loss: 0.7262 - val_acc: 0.5599\n",
      "Epoch 22/50\n",
      " - 14s - loss: 0.5967 - acc: 0.6748 - val_loss: 0.7060 - val_acc: 0.5628\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.5992 - acc: 0.6737 - val_loss: 0.7158 - val_acc: 0.5579\n",
      "Epoch 24/50\n",
      " - 8s - loss: 0.6016 - acc: 0.6722 - val_loss: 0.7197 - val_acc: 0.5517\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5961 - acc: 0.6728 - val_loss: 0.7122 - val_acc: 0.5470\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5943 - acc: 0.6730 - val_loss: 0.7213 - val_acc: 0.5589\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.5932 - acc: 0.6772 - val_loss: 0.7054 - val_acc: 0.5577\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.5948 - acc: 0.6717 - val_loss: 0.7055 - val_acc: 0.5550\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5911 - acc: 0.6708 - val_loss: 0.7032 - val_acc: 0.5270\n",
      "Epoch 30/50\n",
      " - 9s - loss: 0.5947 - acc: 0.6716 - val_loss: 0.7080 - val_acc: 0.5523\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.5938 - acc: 0.6732 - val_loss: 0.7158 - val_acc: 0.5539\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.5959 - acc: 0.6755 - val_loss: 0.6965 - val_acc: 0.5689\n",
      "Epoch 33/50\n",
      " - 9s - loss: 0.5940 - acc: 0.6758 - val_loss: 0.6881 - val_acc: 0.5665\n",
      "Epoch 34/50\n",
      " - 9s - loss: 0.5928 - acc: 0.6739 - val_loss: 0.7026 - val_acc: 0.5586\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5959 - acc: 0.6764 - val_loss: 0.7260 - val_acc: 0.5599\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5906 - acc: 0.6753 - val_loss: 0.7003 - val_acc: 0.5496\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5927 - acc: 0.6787 - val_loss: 0.7161 - val_acc: 0.5584\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5982 - acc: 0.6777 - val_loss: 0.7161 - val_acc: 0.5626\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.6000 - acc: 0.6771 - val_loss: 0.7253 - val_acc: 0.5610\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5925 - acc: 0.6772 - val_loss: 0.7097 - val_acc: 0.5656\n",
      "Epoch 41/50\n",
      " - 11s - loss: 0.5979 - acc: 0.6761 - val_loss: 0.7007 - val_acc: 0.5603\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.5941 - acc: 0.6722 - val_loss: 0.7342 - val_acc: 0.5641\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.5973 - acc: 0.6779 - val_loss: 0.7292 - val_acc: 0.5661\n",
      "Epoch 44/50\n",
      " - 11s - loss: 0.5968 - acc: 0.6773 - val_loss: 0.7419 - val_acc: 0.5631\n",
      "Epoch 45/50\n",
      " - 11s - loss: 0.5978 - acc: 0.6796 - val_loss: 0.7270 - val_acc: 0.5622\n",
      "Epoch 46/50\n",
      " - 10s - loss: 0.6004 - acc: 0.6757 - val_loss: 0.7083 - val_acc: 0.5628\n",
      "Epoch 47/50\n",
      " - 10s - loss: 0.6048 - acc: 0.6762 - val_loss: 0.7203 - val_acc: 0.5633\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.6031 - acc: 0.6759 - val_loss: 0.7033 - val_acc: 0.5643\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.6061 - acc: 0.6737 - val_loss: 0.7301 - val_acc: 0.5644\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.6008 - acc: 0.6733 - val_loss: 0.7401 - val_acc: 0.5649\n",
      "12842.0996948  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 12s - loss: 0.6861 - acc: 0.5650 - val_loss: 0.6967 - val_acc: 0.5498\n",
      "Epoch 2/50\n",
      " - 11s - loss: 0.6632 - acc: 0.6090 - val_loss: 0.6959 - val_acc: 0.5248\n",
      "Epoch 3/50\n",
      " - 11s - loss: 0.6578 - acc: 0.6190 - val_loss: 0.7071 - val_acc: 0.5513\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6505 - acc: 0.6272 - val_loss: 0.7077 - val_acc: 0.5389\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.6467 - acc: 0.6280 - val_loss: 0.6986 - val_acc: 0.5299\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.6416 - acc: 0.6356 - val_loss: 0.7020 - val_acc: 0.5222\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.6383 - acc: 0.6390 - val_loss: 0.6990 - val_acc: 0.5360\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6370 - acc: 0.6374 - val_loss: 0.6990 - val_acc: 0.5446\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.6316 - acc: 0.6470 - val_loss: 0.6962 - val_acc: 0.5504\n",
      "Epoch 10/50\n",
      " - 9s - loss: 0.6294 - acc: 0.6475 - val_loss: 0.7247 - val_acc: 0.5220\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.6271 - acc: 0.6491 - val_loss: 0.7117 - val_acc: 0.5115\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.6192 - acc: 0.6526 - val_loss: 0.7022 - val_acc: 0.5451\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.6227 - acc: 0.6508 - val_loss: 0.7078 - val_acc: 0.5512\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.6165 - acc: 0.6545 - val_loss: 0.7145 - val_acc: 0.5518\n",
      "Epoch 15/50\n",
      " - 8s - loss: 0.6109 - acc: 0.6568 - val_loss: 0.7174 - val_acc: 0.5598\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.6080 - acc: 0.6592 - val_loss: 0.7003 - val_acc: 0.5487\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.6111 - acc: 0.6589 - val_loss: 0.7190 - val_acc: 0.5537\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.6100 - acc: 0.6581 - val_loss: 0.7259 - val_acc: 0.5509\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.6067 - acc: 0.6628 - val_loss: 0.7364 - val_acc: 0.5626\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.6057 - acc: 0.6640 - val_loss: 0.7337 - val_acc: 0.5400\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.6014 - acc: 0.6635 - val_loss: 0.7093 - val_acc: 0.5574\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.5975 - acc: 0.6631 - val_loss: 0.7185 - val_acc: 0.5556\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.5971 - acc: 0.6666 - val_loss: 0.7226 - val_acc: 0.5554\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5968 - acc: 0.6693 - val_loss: 0.7294 - val_acc: 0.5619\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5969 - acc: 0.6731 - val_loss: 0.7391 - val_acc: 0.5591\n",
      "Epoch 26/50\n",
      " - 9s - loss: 0.5985 - acc: 0.6747 - val_loss: 0.7527 - val_acc: 0.5569\n",
      "Epoch 27/50\n",
      " - 9s - loss: 0.6005 - acc: 0.6744 - val_loss: 0.7409 - val_acc: 0.5451\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.6029 - acc: 0.6740 - val_loss: 0.7577 - val_acc: 0.5654\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5932 - acc: 0.6748 - val_loss: 0.7535 - val_acc: 0.5636\n",
      "Epoch 30/50\n",
      " - 9s - loss: 0.5995 - acc: 0.6733 - val_loss: 0.7646 - val_acc: 0.5605\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.5991 - acc: 0.6655 - val_loss: 0.7239 - val_acc: 0.5643\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.5959 - acc: 0.6677 - val_loss: 0.7219 - val_acc: 0.5652\n",
      "Epoch 33/50\n",
      " - 9s - loss: 0.5978 - acc: 0.6700 - val_loss: 0.7343 - val_acc: 0.5652\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5956 - acc: 0.6724 - val_loss: 0.7202 - val_acc: 0.5657\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5963 - acc: 0.6726 - val_loss: 0.7037 - val_acc: 0.5571\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5886 - acc: 0.6736 - val_loss: 0.7041 - val_acc: 0.5622\n",
      "Epoch 37/50\n",
      " - 10s - loss: 0.5905 - acc: 0.6713 - val_loss: 0.6949 - val_acc: 0.5715\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.5896 - acc: 0.6729 - val_loss: 0.7031 - val_acc: 0.5684\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5922 - acc: 0.6779 - val_loss: 0.6917 - val_acc: 0.5668\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5952 - acc: 0.6773 - val_loss: 0.6947 - val_acc: 0.5584\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5948 - acc: 0.6750 - val_loss: 0.7111 - val_acc: 0.5629\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.5931 - acc: 0.6738 - val_loss: 0.7163 - val_acc: 0.5668\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.5947 - acc: 0.6756 - val_loss: 0.7103 - val_acc: 0.5629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      " - 9s - loss: 0.5912 - acc: 0.6754 - val_loss: 0.7066 - val_acc: 0.5677\n",
      "Epoch 45/50\n",
      " - 9s - loss: 0.5915 - acc: 0.6721 - val_loss: 0.6955 - val_acc: 0.5433\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.5896 - acc: 0.6758 - val_loss: 0.6877 - val_acc: 0.5640\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5830 - acc: 0.6731 - val_loss: 0.6945 - val_acc: 0.5655\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.5838 - acc: 0.6716 - val_loss: 0.6889 - val_acc: 0.5679\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.5870 - acc: 0.6756 - val_loss: 0.6894 - val_acc: 0.5598\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5866 - acc: 0.6751 - val_loss: 0.6899 - val_acc: 0.5668\n",
      "474.232444199999  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.6805 - acc: 0.5746 - val_loss: 0.7010 - val_acc: 0.5137\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.6510 - acc: 0.6074 - val_loss: 0.7051 - val_acc: 0.5265\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6318 - acc: 0.6279 - val_loss: 0.7231 - val_acc: 0.5258\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6199 - acc: 0.6403 - val_loss: 0.7149 - val_acc: 0.5417\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6170 - acc: 0.6487 - val_loss: 0.7334 - val_acc: 0.5400\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.6074 - acc: 0.6524 - val_loss: 0.7249 - val_acc: 0.5564\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6026 - acc: 0.6555 - val_loss: 0.7049 - val_acc: 0.5568\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.5960 - acc: 0.6587 - val_loss: 0.7003 - val_acc: 0.5497\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.5938 - acc: 0.6633 - val_loss: 0.7057 - val_acc: 0.5585\n",
      "Epoch 10/50\n",
      " - 9s - loss: 0.5967 - acc: 0.6681 - val_loss: 0.7105 - val_acc: 0.5623\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.5965 - acc: 0.6657 - val_loss: 0.7092 - val_acc: 0.5643\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.5929 - acc: 0.6667 - val_loss: 0.7001 - val_acc: 0.5617\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.5941 - acc: 0.6670 - val_loss: 0.7117 - val_acc: 0.5536\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.5945 - acc: 0.6633 - val_loss: 0.7182 - val_acc: 0.5577\n",
      "Epoch 15/50\n",
      " - 10s - loss: 0.5919 - acc: 0.6657 - val_loss: 0.6985 - val_acc: 0.5648\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.5929 - acc: 0.6697 - val_loss: 0.7160 - val_acc: 0.5671\n",
      "Epoch 17/50\n",
      " - 10s - loss: 0.5916 - acc: 0.6654 - val_loss: 0.7490 - val_acc: 0.5670\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.5932 - acc: 0.6701 - val_loss: 0.7033 - val_acc: 0.5630\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.5925 - acc: 0.6721 - val_loss: 0.6910 - val_acc: 0.5667\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.5884 - acc: 0.6678 - val_loss: 0.6924 - val_acc: 0.5562\n",
      "Epoch 21/50\n",
      " - 9s - loss: 0.5904 - acc: 0.6686 - val_loss: 0.6908 - val_acc: 0.5625\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.5870 - acc: 0.6711 - val_loss: 0.6999 - val_acc: 0.5689\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.5914 - acc: 0.6699 - val_loss: 0.6938 - val_acc: 0.5627\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5967 - acc: 0.6719 - val_loss: 0.6958 - val_acc: 0.5611\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.5957 - acc: 0.6728 - val_loss: 0.7445 - val_acc: 0.5633\n",
      "Epoch 26/50\n",
      " - 9s - loss: 0.5944 - acc: 0.6703 - val_loss: 0.7032 - val_acc: 0.5635\n",
      "Epoch 27/50\n",
      " - 8s - loss: 0.5902 - acc: 0.6730 - val_loss: 0.6939 - val_acc: 0.5678\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.5903 - acc: 0.6711 - val_loss: 0.7037 - val_acc: 0.5645\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5895 - acc: 0.6709 - val_loss: 0.6878 - val_acc: 0.5620\n",
      "Epoch 30/50\n",
      " - 9s - loss: 0.5923 - acc: 0.6723 - val_loss: 0.7305 - val_acc: 0.5656\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.5963 - acc: 0.6744 - val_loss: 0.7264 - val_acc: 0.5666\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.5982 - acc: 0.6746 - val_loss: 0.7173 - val_acc: 0.5626\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.5999 - acc: 0.6701 - val_loss: 0.7074 - val_acc: 0.5608\n",
      "Epoch 34/50\n",
      " - 9s - loss: 0.5931 - acc: 0.6706 - val_loss: 0.6884 - val_acc: 0.5673\n",
      "Epoch 35/50\n",
      " - 10s - loss: 0.5916 - acc: 0.6705 - val_loss: 0.6900 - val_acc: 0.5679\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5877 - acc: 0.6728 - val_loss: 0.6842 - val_acc: 0.5704\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5868 - acc: 0.6701 - val_loss: 0.6858 - val_acc: 0.5648\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5863 - acc: 0.6715 - val_loss: 0.6810 - val_acc: 0.5717\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.5845 - acc: 0.6738 - val_loss: 0.6828 - val_acc: 0.5423\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5907 - acc: 0.6721 - val_loss: 0.6886 - val_acc: 0.5696\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5941 - acc: 0.6746 - val_loss: 0.6826 - val_acc: 0.5669\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.5863 - acc: 0.6725 - val_loss: 0.6850 - val_acc: 0.5685\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.5884 - acc: 0.6725 - val_loss: 0.6803 - val_acc: 0.5650\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5898 - acc: 0.6737 - val_loss: 0.6843 - val_acc: 0.5653\n",
      "Epoch 45/50\n",
      " - 9s - loss: 0.5925 - acc: 0.6767 - val_loss: 0.6866 - val_acc: 0.5654\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.5874 - acc: 0.6746 - val_loss: 0.6810 - val_acc: 0.5710\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5850 - acc: 0.6765 - val_loss: 0.6850 - val_acc: 0.5723\n",
      "Epoch 48/50\n",
      " - 9s - loss: 0.5864 - acc: 0.6789 - val_loss: 0.6846 - val_acc: 0.5703\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.5879 - acc: 0.6752 - val_loss: 0.6850 - val_acc: 0.5705\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5878 - acc: 0.6755 - val_loss: 0.6841 - val_acc: 0.5707\n",
      "469.7577056000009  seconds\n"
     ]
    }
   ],
   "source": [
    "model5 = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    hist = model.fit(xtrain, ytrain, epochs=50, batch_size=64, validation_data=(xtest5, ytest5), verbose=2)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    print(elapsed, \" seconds\")\n",
    "    model5.append(hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.6967 - acc: 0.5628 - val_loss: 0.6835 - val_acc: 0.5590\n",
      "Epoch 2/50\n",
      " - 7s - loss: 0.6585 - acc: 0.6178 - val_loss: 0.6597 - val_acc: 0.6243\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.6492 - acc: 0.6365 - val_loss: 0.6730 - val_acc: 0.5905\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6483 - acc: 0.6204 - val_loss: 0.6750 - val_acc: 0.5834\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.6374 - acc: 0.6384 - val_loss: 0.6509 - val_acc: 0.6100\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.6260 - acc: 0.6505 - val_loss: 0.6434 - val_acc: 0.6479\n",
      "Epoch 7/50\n",
      " - 7s - loss: 0.6238 - acc: 0.6507 - val_loss: 0.6493 - val_acc: 0.6361\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6175 - acc: 0.6555 - val_loss: 0.6402 - val_acc: 0.6372\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.6205 - acc: 0.6410 - val_loss: 0.6414 - val_acc: 0.5955\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.6074 - acc: 0.6629 - val_loss: 0.6724 - val_acc: 0.6204\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.6111 - acc: 0.6681 - val_loss: 0.6762 - val_acc: 0.6267\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.6128 - acc: 0.6622 - val_loss: 0.6841 - val_acc: 0.6169\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.6078 - acc: 0.6696 - val_loss: 0.6609 - val_acc: 0.6382\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.6055 - acc: 0.6701 - val_loss: 0.6692 - val_acc: 0.6290\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6034 - acc: 0.6678 - val_loss: 0.6567 - val_acc: 0.6430\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.5987 - acc: 0.6679 - val_loss: 0.6462 - val_acc: 0.6487\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.6027 - acc: 0.6700 - val_loss: 0.6574 - val_acc: 0.6281\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.6017 - acc: 0.6683 - val_loss: 0.6283 - val_acc: 0.6415\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.5953 - acc: 0.6727 - val_loss: 0.6320 - val_acc: 0.6442\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.5920 - acc: 0.6754 - val_loss: 0.6556 - val_acc: 0.6437\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.5979 - acc: 0.6722 - val_loss: 0.6560 - val_acc: 0.6526\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.5930 - acc: 0.6767 - val_loss: 0.6458 - val_acc: 0.6210\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.5976 - acc: 0.6724 - val_loss: 0.6386 - val_acc: 0.6381\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5926 - acc: 0.6717 - val_loss: 0.6382 - val_acc: 0.6290\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5933 - acc: 0.6723 - val_loss: 0.6248 - val_acc: 0.6508\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5984 - acc: 0.6651 - val_loss: 0.6377 - val_acc: 0.6341\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.5908 - acc: 0.6689 - val_loss: 0.6324 - val_acc: 0.6357\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.5927 - acc: 0.6773 - val_loss: 0.6358 - val_acc: 0.6485\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5933 - acc: 0.6743 - val_loss: 0.6322 - val_acc: 0.6368\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.5941 - acc: 0.6803 - val_loss: 0.6348 - val_acc: 0.6455\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.6014 - acc: 0.6655 - val_loss: 0.6272 - val_acc: 0.6510\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.5943 - acc: 0.6733 - val_loss: 0.6329 - val_acc: 0.6397\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5958 - acc: 0.6735 - val_loss: 0.6284 - val_acc: 0.6399\n",
      "Epoch 34/50\n",
      " - 12s - loss: 0.5987 - acc: 0.6762 - val_loss: 0.6410 - val_acc: 0.6236\n",
      "Epoch 35/50\n",
      " - 10s - loss: 0.5956 - acc: 0.6776 - val_loss: 0.6504 - val_acc: 0.6315\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5908 - acc: 0.6783 - val_loss: 0.6322 - val_acc: 0.6326\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5916 - acc: 0.6767 - val_loss: 0.6322 - val_acc: 0.6316\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5972 - acc: 0.6752 - val_loss: 0.6470 - val_acc: 0.6523\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.6003 - acc: 0.6759 - val_loss: 0.6544 - val_acc: 0.6411\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.5931 - acc: 0.6761 - val_loss: 0.6514 - val_acc: 0.6493\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.5959 - acc: 0.6793 - val_loss: 0.6439 - val_acc: 0.6280\n",
      "Epoch 42/50\n",
      " - 9s - loss: 0.5879 - acc: 0.6763 - val_loss: 0.6269 - val_acc: 0.6388\n",
      "Epoch 43/50\n",
      " - 8s - loss: 0.5910 - acc: 0.6769 - val_loss: 0.6343 - val_acc: 0.6355\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5872 - acc: 0.6767 - val_loss: 0.6282 - val_acc: 0.6201\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5906 - acc: 0.6771 - val_loss: 0.6480 - val_acc: 0.6425\n",
      "Epoch 46/50\n",
      " - 10s - loss: 0.5966 - acc: 0.6767 - val_loss: 0.6348 - val_acc: 0.6368\n",
      "Epoch 47/50\n",
      " - 10s - loss: 0.5933 - acc: 0.6752 - val_loss: 0.6331 - val_acc: 0.6436\n",
      "Epoch 48/50\n",
      " - 9s - loss: 0.5994 - acc: 0.6747 - val_loss: 0.6307 - val_acc: 0.6367\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.5911 - acc: 0.6703 - val_loss: 0.6357 - val_acc: 0.6418\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5909 - acc: 0.6739 - val_loss: 0.6366 - val_acc: 0.6452\n",
      "465.3187024000008  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 9s - loss: 0.6892 - acc: 0.5595 - val_loss: 0.6818 - val_acc: 0.5611\n",
      "Epoch 2/50\n",
      " - 9s - loss: 0.6568 - acc: 0.6127 - val_loss: 0.6756 - val_acc: 0.5447\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6486 - acc: 0.6129 - val_loss: 0.6707 - val_acc: 0.6047\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6438 - acc: 0.6186 - val_loss: 0.6618 - val_acc: 0.6166\n",
      "Epoch 5/50\n",
      " - 11s - loss: 0.6331 - acc: 0.6314 - val_loss: 0.6483 - val_acc: 0.6241\n",
      "Epoch 6/50\n",
      " - 11s - loss: 0.6193 - acc: 0.6434 - val_loss: 0.6643 - val_acc: 0.5978\n",
      "Epoch 7/50\n",
      " - 11s - loss: 0.6235 - acc: 0.6394 - val_loss: 0.6651 - val_acc: 0.6101\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.6144 - acc: 0.6506 - val_loss: 0.6572 - val_acc: 0.6293\n",
      "Epoch 9/50\n",
      " - 12s - loss: 0.6088 - acc: 0.6526 - val_loss: 0.6837 - val_acc: 0.5944\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.5987 - acc: 0.6587 - val_loss: 0.6486 - val_acc: 0.6394\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.5981 - acc: 0.6603 - val_loss: 0.6444 - val_acc: 0.6455\n",
      "Epoch 12/50\n",
      " - 11s - loss: 0.5943 - acc: 0.6633 - val_loss: 0.6403 - val_acc: 0.6295\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.5923 - acc: 0.6657 - val_loss: 0.6413 - val_acc: 0.6387\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.5892 - acc: 0.6679 - val_loss: 0.6368 - val_acc: 0.6359\n",
      "Epoch 15/50\n",
      " - 10s - loss: 0.5888 - acc: 0.6701 - val_loss: 0.6361 - val_acc: 0.6335\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.5898 - acc: 0.6714 - val_loss: 0.6419 - val_acc: 0.6196\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.5946 - acc: 0.6694 - val_loss: 0.6638 - val_acc: 0.6332\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.5907 - acc: 0.6685 - val_loss: 0.6478 - val_acc: 0.6397\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.5891 - acc: 0.6727 - val_loss: 0.6392 - val_acc: 0.6345\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.5867 - acc: 0.6712 - val_loss: 0.6375 - val_acc: 0.6437\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.5888 - acc: 0.6746 - val_loss: 0.6407 - val_acc: 0.6274\n",
      "Epoch 22/50\n",
      " - 9s - loss: 0.5911 - acc: 0.6732 - val_loss: 0.6404 - val_acc: 0.6196\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.5891 - acc: 0.6671 - val_loss: 0.6397 - val_acc: 0.6477\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5924 - acc: 0.6726 - val_loss: 0.6360 - val_acc: 0.6373\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5938 - acc: 0.6735 - val_loss: 0.6370 - val_acc: 0.6480\n",
      "Epoch 26/50\n",
      " - 8s - loss: 0.5927 - acc: 0.6716 - val_loss: 0.6350 - val_acc: 0.6493\n",
      "Epoch 27/50\n",
      " - 9s - loss: 0.5910 - acc: 0.6722 - val_loss: 0.6410 - val_acc: 0.6504\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.5895 - acc: 0.6725 - val_loss: 0.6336 - val_acc: 0.6303\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5899 - acc: 0.6741 - val_loss: 0.6343 - val_acc: 0.6406\n",
      "Epoch 30/50\n",
      " - 11s - loss: 0.5957 - acc: 0.6758 - val_loss: 0.6508 - val_acc: 0.6381\n",
      "Epoch 31/50\n",
      " - 11s - loss: 0.5951 - acc: 0.6763 - val_loss: 0.6302 - val_acc: 0.6346\n",
      "Epoch 32/50\n",
      " - 11s - loss: 0.5854 - acc: 0.6716 - val_loss: 0.6272 - val_acc: 0.6374\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5932 - acc: 0.6743 - val_loss: 0.6337 - val_acc: 0.6240\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5867 - acc: 0.6719 - val_loss: 0.6358 - val_acc: 0.6523\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5967 - acc: 0.6766 - val_loss: 0.6372 - val_acc: 0.6550\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.5926 - acc: 0.6759 - val_loss: 0.6300 - val_acc: 0.6331\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5939 - acc: 0.6765 - val_loss: 0.6384 - val_acc: 0.6463\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.5953 - acc: 0.6768 - val_loss: 0.6301 - val_acc: 0.6487\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.6006 - acc: 0.6783 - val_loss: 0.6450 - val_acc: 0.6451\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.5996 - acc: 0.6762 - val_loss: 0.6381 - val_acc: 0.6459\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.5987 - acc: 0.6763 - val_loss: 0.6267 - val_acc: 0.6458\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.5919 - acc: 0.6746 - val_loss: 0.6285 - val_acc: 0.6388\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.5856 - acc: 0.6752 - val_loss: 0.6282 - val_acc: 0.6376\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5828 - acc: 0.6772 - val_loss: 0.6247 - val_acc: 0.6461\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5870 - acc: 0.6761 - val_loss: 0.6363 - val_acc: 0.6419\n",
      "Epoch 46/50\n",
      " - 11s - loss: 0.5931 - acc: 0.6779 - val_loss: 0.6363 - val_acc: 0.6525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      " - 10s - loss: 0.5953 - acc: 0.6780 - val_loss: 0.6347 - val_acc: 0.6465\n",
      "Epoch 48/50\n",
      " - 11s - loss: 0.5987 - acc: 0.6775 - val_loss: 0.6298 - val_acc: 0.6511\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.5886 - acc: 0.6765 - val_loss: 0.6259 - val_acc: 0.6469\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5930 - acc: 0.6790 - val_loss: 0.6340 - val_acc: 0.6408\n",
      "499.52693940000063  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.6982 - acc: 0.5294 - val_loss: 0.6909 - val_acc: 0.5472\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.6871 - acc: 0.5438 - val_loss: 0.6886 - val_acc: 0.5480\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6775 - acc: 0.5627 - val_loss: 0.6788 - val_acc: 0.5681\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6619 - acc: 0.6021 - val_loss: 0.6795 - val_acc: 0.5601\n",
      "Epoch 5/50\n",
      " - 11s - loss: 0.6648 - acc: 0.6005 - val_loss: 0.6865 - val_acc: 0.5639\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.6504 - acc: 0.6126 - val_loss: 0.6694 - val_acc: 0.5878\n",
      "Epoch 7/50\n",
      " - 11s - loss: 0.6409 - acc: 0.6336 - val_loss: 0.6814 - val_acc: 0.5738\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.6374 - acc: 0.6317 - val_loss: 0.6726 - val_acc: 0.6069\n",
      "Epoch 9/50\n",
      " - 10s - loss: 0.6353 - acc: 0.6363 - val_loss: 0.6665 - val_acc: 0.6113\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.6257 - acc: 0.6457 - val_loss: 0.6618 - val_acc: 0.6207\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.6194 - acc: 0.6521 - val_loss: 0.6688 - val_acc: 0.5995\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.6175 - acc: 0.6548 - val_loss: 0.6729 - val_acc: 0.6234\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.6218 - acc: 0.6554 - val_loss: 0.6684 - val_acc: 0.6066\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.6182 - acc: 0.6605 - val_loss: 0.6668 - val_acc: 0.6172\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6172 - acc: 0.6572 - val_loss: 0.6711 - val_acc: 0.6157\n",
      "Epoch 16/50\n",
      " - 9s - loss: 0.6064 - acc: 0.6580 - val_loss: 0.6665 - val_acc: 0.6052\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.6053 - acc: 0.6525 - val_loss: 0.6624 - val_acc: 0.6109\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.6073 - acc: 0.6625 - val_loss: 0.6569 - val_acc: 0.6197\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.6048 - acc: 0.6607 - val_loss: 0.6688 - val_acc: 0.6087\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.6079 - acc: 0.6651 - val_loss: 0.6638 - val_acc: 0.6187\n",
      "Epoch 21/50\n",
      " - 9s - loss: 0.6033 - acc: 0.6649 - val_loss: 0.6820 - val_acc: 0.6135\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.6034 - acc: 0.6681 - val_loss: 0.6775 - val_acc: 0.5904\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.6029 - acc: 0.6683 - val_loss: 0.6533 - val_acc: 0.6128\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.5953 - acc: 0.6668 - val_loss: 0.6339 - val_acc: 0.6497\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.5923 - acc: 0.6681 - val_loss: 0.6554 - val_acc: 0.6338\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5934 - acc: 0.6676 - val_loss: 0.6456 - val_acc: 0.6388\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.5936 - acc: 0.6687 - val_loss: 0.6428 - val_acc: 0.6314\n",
      "Epoch 28/50\n",
      " - 11s - loss: 0.5961 - acc: 0.6739 - val_loss: 0.6473 - val_acc: 0.6351\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5950 - acc: 0.6726 - val_loss: 0.6437 - val_acc: 0.6267\n",
      "Epoch 30/50\n",
      " - 11s - loss: 0.5931 - acc: 0.6707 - val_loss: 0.6294 - val_acc: 0.6327\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.5934 - acc: 0.6711 - val_loss: 0.6529 - val_acc: 0.6248\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.5998 - acc: 0.6725 - val_loss: 0.6433 - val_acc: 0.6278\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.5921 - acc: 0.6726 - val_loss: 0.6512 - val_acc: 0.6385\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5898 - acc: 0.6687 - val_loss: 0.6353 - val_acc: 0.6437\n",
      "Epoch 35/50\n",
      " - 10s - loss: 0.5894 - acc: 0.6710 - val_loss: 0.6285 - val_acc: 0.6433\n",
      "Epoch 36/50\n",
      " - 10s - loss: 0.5921 - acc: 0.6759 - val_loss: 0.6425 - val_acc: 0.6433\n",
      "Epoch 37/50\n",
      " - 10s - loss: 0.5922 - acc: 0.6707 - val_loss: 0.6342 - val_acc: 0.6449\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.5916 - acc: 0.6664 - val_loss: 0.6380 - val_acc: 0.6363\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.5886 - acc: 0.6690 - val_loss: 0.6339 - val_acc: 0.6241\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.5960 - acc: 0.6739 - val_loss: 0.6492 - val_acc: 0.6368\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5917 - acc: 0.6718 - val_loss: 0.6362 - val_acc: 0.6313\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.6017 - acc: 0.6747 - val_loss: 0.6474 - val_acc: 0.6402\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.5909 - acc: 0.6776 - val_loss: 0.6242 - val_acc: 0.6328\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5869 - acc: 0.6755 - val_loss: 0.6226 - val_acc: 0.6435\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5930 - acc: 0.6723 - val_loss: 0.6313 - val_acc: 0.6472\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.6022 - acc: 0.6736 - val_loss: 0.6415 - val_acc: 0.6482\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5962 - acc: 0.6755 - val_loss: 0.6409 - val_acc: 0.6508\n",
      "Epoch 48/50\n",
      " - 9s - loss: 0.5962 - acc: 0.6715 - val_loss: 0.6313 - val_acc: 0.6379\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.5955 - acc: 0.6699 - val_loss: 0.6360 - val_acc: 0.6500\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.5977 - acc: 0.6721 - val_loss: 0.6387 - val_acc: 0.6295\n",
      "489.12149750000026  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 10s - loss: 0.6998 - acc: 0.5467 - val_loss: 0.6842 - val_acc: 0.5659\n",
      "Epoch 2/50\n",
      " - 9s - loss: 0.6630 - acc: 0.6065 - val_loss: 0.6822 - val_acc: 0.5670\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6524 - acc: 0.6235 - val_loss: 0.6839 - val_acc: 0.5629\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6439 - acc: 0.6375 - val_loss: 0.6759 - val_acc: 0.5688\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6322 - acc: 0.6500 - val_loss: 0.6735 - val_acc: 0.5948\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6272 - acc: 0.6484 - val_loss: 0.6771 - val_acc: 0.5648\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6196 - acc: 0.6534 - val_loss: 0.6576 - val_acc: 0.6088\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.6133 - acc: 0.6603 - val_loss: 0.6589 - val_acc: 0.6110\n",
      "Epoch 9/50\n",
      " - 10s - loss: 0.6087 - acc: 0.6613 - val_loss: 0.6534 - val_acc: 0.5876\n",
      "Epoch 10/50\n",
      " - 9s - loss: 0.6046 - acc: 0.6606 - val_loss: 0.6538 - val_acc: 0.5773\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.6052 - acc: 0.6590 - val_loss: 0.6717 - val_acc: 0.5936\n",
      "Epoch 12/50\n",
      " - 11s - loss: 0.6028 - acc: 0.6664 - val_loss: 0.6483 - val_acc: 0.6226\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.5990 - acc: 0.6650 - val_loss: 0.6562 - val_acc: 0.6351\n",
      "Epoch 14/50\n",
      " - 11s - loss: 0.6027 - acc: 0.6645 - val_loss: 0.6701 - val_acc: 0.6211\n",
      "Epoch 15/50\n",
      " - 10s - loss: 0.6006 - acc: 0.6673 - val_loss: 0.6693 - val_acc: 0.6188\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.5991 - acc: 0.6706 - val_loss: 0.6533 - val_acc: 0.6258\n",
      "Epoch 17/50\n",
      " - 10s - loss: 0.5962 - acc: 0.6730 - val_loss: 0.6470 - val_acc: 0.6137\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.5965 - acc: 0.6714 - val_loss: 0.6411 - val_acc: 0.6423\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.5990 - acc: 0.6708 - val_loss: 0.6384 - val_acc: 0.6458\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.5987 - acc: 0.6710 - val_loss: 0.6512 - val_acc: 0.6388\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.5940 - acc: 0.6681 - val_loss: 0.6457 - val_acc: 0.6328\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.5910 - acc: 0.6688 - val_loss: 0.6469 - val_acc: 0.6019\n",
      "Epoch 23/50\n",
      " - 11s - loss: 0.5977 - acc: 0.6692 - val_loss: 0.6712 - val_acc: 0.6103\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.5988 - acc: 0.6717 - val_loss: 0.6497 - val_acc: 0.6234\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.5991 - acc: 0.6726 - val_loss: 0.6396 - val_acc: 0.6465\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5969 - acc: 0.6761 - val_loss: 0.6316 - val_acc: 0.6392\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.5987 - acc: 0.6746 - val_loss: 0.6563 - val_acc: 0.6360\n",
      "Epoch 28/50\n",
      " - 11s - loss: 0.6000 - acc: 0.6729 - val_loss: 0.6411 - val_acc: 0.6276\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5973 - acc: 0.6706 - val_loss: 0.6458 - val_acc: 0.6379\n",
      "Epoch 30/50\n",
      " - 11s - loss: 0.5964 - acc: 0.6756 - val_loss: 0.6391 - val_acc: 0.6397\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.5892 - acc: 0.6768 - val_loss: 0.6324 - val_acc: 0.6288\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.5907 - acc: 0.6758 - val_loss: 0.6386 - val_acc: 0.6439\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5923 - acc: 0.6742 - val_loss: 0.6287 - val_acc: 0.6402\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5952 - acc: 0.6721 - val_loss: 0.6319 - val_acc: 0.6465\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5973 - acc: 0.6732 - val_loss: 0.6557 - val_acc: 0.6447\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5967 - acc: 0.6742 - val_loss: 0.6521 - val_acc: 0.6424\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5943 - acc: 0.6764 - val_loss: 0.6425 - val_acc: 0.6451\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.6000 - acc: 0.6745 - val_loss: 0.6497 - val_acc: 0.6400\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5940 - acc: 0.6752 - val_loss: 0.6335 - val_acc: 0.6360\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5925 - acc: 0.6741 - val_loss: 0.6518 - val_acc: 0.6356\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.5957 - acc: 0.6779 - val_loss: 0.6273 - val_acc: 0.6420\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 0.5850 - acc: 0.6740 - val_loss: 0.6268 - val_acc: 0.6423\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.5911 - acc: 0.6760 - val_loss: 0.6321 - val_acc: 0.6500\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5910 - acc: 0.6768 - val_loss: 0.6226 - val_acc: 0.6523\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5931 - acc: 0.6761 - val_loss: 0.6355 - val_acc: 0.6476\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.5896 - acc: 0.6768 - val_loss: 0.6283 - val_acc: 0.6460\n",
      "Epoch 47/50\n",
      " - 10s - loss: 0.5843 - acc: 0.6777 - val_loss: 0.6252 - val_acc: 0.6448\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.5844 - acc: 0.6748 - val_loss: 0.6329 - val_acc: 0.6374\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.5896 - acc: 0.6751 - val_loss: 0.6275 - val_acc: 0.6416\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5889 - acc: 0.6747 - val_loss: 0.6262 - val_acc: 0.6482\n",
      "495.01332900000034  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.6877 - acc: 0.5658 - val_loss: 0.6769 - val_acc: 0.5730\n",
      "Epoch 2/50\n",
      " - 9s - loss: 0.6518 - acc: 0.6071 - val_loss: 0.6925 - val_acc: 0.5159\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6351 - acc: 0.6244 - val_loss: 0.6824 - val_acc: 0.5682\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6284 - acc: 0.6378 - val_loss: 0.6716 - val_acc: 0.5708\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6194 - acc: 0.6402 - val_loss: 0.6656 - val_acc: 0.5791\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.6120 - acc: 0.6478 - val_loss: 0.6623 - val_acc: 0.5752\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6001 - acc: 0.6528 - val_loss: 0.6447 - val_acc: 0.6064\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.5950 - acc: 0.6558 - val_loss: 0.6397 - val_acc: 0.6199\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.5922 - acc: 0.6610 - val_loss: 0.6326 - val_acc: 0.6453\n",
      "Epoch 10/50\n",
      " - 9s - loss: 0.5928 - acc: 0.6610 - val_loss: 0.6491 - val_acc: 0.6325\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.5915 - acc: 0.6659 - val_loss: 0.6392 - val_acc: 0.6417\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.5949 - acc: 0.6639 - val_loss: 0.6342 - val_acc: 0.6494\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.5934 - acc: 0.6598 - val_loss: 0.6308 - val_acc: 0.6423\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.5892 - acc: 0.6657 - val_loss: 0.6315 - val_acc: 0.6280\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.5920 - acc: 0.6681 - val_loss: 0.6369 - val_acc: 0.6394\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.5910 - acc: 0.6680 - val_loss: 0.6473 - val_acc: 0.6464\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.5906 - acc: 0.6693 - val_loss: 0.6505 - val_acc: 0.6366\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.5905 - acc: 0.6718 - val_loss: 0.6337 - val_acc: 0.6364\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.5908 - acc: 0.6704 - val_loss: 0.6395 - val_acc: 0.6486\n",
      "Epoch 20/50\n",
      " - 9s - loss: 0.5907 - acc: 0.6720 - val_loss: 0.6316 - val_acc: 0.6466\n",
      "Epoch 21/50\n",
      " - 9s - loss: 0.5892 - acc: 0.6749 - val_loss: 0.6346 - val_acc: 0.6368\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.5903 - acc: 0.6731 - val_loss: 0.6343 - val_acc: 0.6364\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.5879 - acc: 0.6732 - val_loss: 0.6255 - val_acc: 0.6456\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5900 - acc: 0.6720 - val_loss: 0.6325 - val_acc: 0.6440\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.5952 - acc: 0.6746 - val_loss: 0.6532 - val_acc: 0.6334\n",
      "Epoch 26/50\n",
      " - 9s - loss: 0.5956 - acc: 0.6750 - val_loss: 0.6292 - val_acc: 0.6446\n",
      "Epoch 27/50\n",
      " - 9s - loss: 0.5890 - acc: 0.6732 - val_loss: 0.6327 - val_acc: 0.6400\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.5940 - acc: 0.6731 - val_loss: 0.6283 - val_acc: 0.6464\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5857 - acc: 0.6713 - val_loss: 0.6250 - val_acc: 0.6332\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.5888 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.6437\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.5934 - acc: 0.6742 - val_loss: 0.6412 - val_acc: 0.6397\n",
      "Epoch 32/50\n",
      " - 11s - loss: 0.5929 - acc: 0.6728 - val_loss: 0.6364 - val_acc: 0.6476\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5878 - acc: 0.6718 - val_loss: 0.6248 - val_acc: 0.6465\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5845 - acc: 0.6723 - val_loss: 0.6273 - val_acc: 0.6235\n",
      "Epoch 35/50\n",
      " - 10s - loss: 0.5887 - acc: 0.6747 - val_loss: 0.6355 - val_acc: 0.6473\n",
      "Epoch 36/50\n",
      " - 10s - loss: 0.5958 - acc: 0.6760 - val_loss: 0.6560 - val_acc: 0.6428\n",
      "Epoch 37/50\n",
      " - 10s - loss: 0.5943 - acc: 0.6753 - val_loss: 0.6411 - val_acc: 0.6465\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.5969 - acc: 0.6756 - val_loss: 0.6348 - val_acc: 0.6434\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.5940 - acc: 0.6738 - val_loss: 0.6281 - val_acc: 0.6515\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.5930 - acc: 0.6746 - val_loss: 0.6319 - val_acc: 0.6507\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.5893 - acc: 0.6759 - val_loss: 0.6297 - val_acc: 0.6500\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.5931 - acc: 0.6756 - val_loss: 0.6408 - val_acc: 0.6448\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.5945 - acc: 0.6768 - val_loss: 0.6308 - val_acc: 0.6503\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5898 - acc: 0.6745 - val_loss: 0.6300 - val_acc: 0.6481\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5890 - acc: 0.6755 - val_loss: 0.6332 - val_acc: 0.6369\n",
      "Epoch 46/50\n",
      " - 10s - loss: 0.5840 - acc: 0.6741 - val_loss: 0.6268 - val_acc: 0.6364\n",
      "Epoch 47/50\n",
      " - 10s - loss: 0.5992 - acc: 0.6744 - val_loss: 0.6420 - val_acc: 0.6446\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.5973 - acc: 0.6744 - val_loss: 0.6258 - val_acc: 0.6469\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.5956 - acc: 0.6721 - val_loss: 0.6195 - val_acc: 0.6475\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.5939 - acc: 0.6760 - val_loss: 0.6237 - val_acc: 0.6472\n",
      "474.3756757000001  seconds\n"
     ]
    }
   ],
   "source": [
    "model10 = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    hist = model.fit(xtrain, ytrain, epochs=50, batch_size=64, validation_data=(xtest10, ytest10), verbose=1)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    print(elapsed, \" seconds\")\n",
    "    model10.append(hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 0.7035 - acc: 0.5415 - val_loss: 0.6439 - val_acc: 0.6715\n",
      "Epoch 2/50\n",
      " - 7s - loss: 0.6672 - acc: 0.6064 - val_loss: 0.6330 - val_acc: 0.6835\n",
      "Epoch 3/50\n",
      " - 7s - loss: 0.6576 - acc: 0.6262 - val_loss: 0.6780 - val_acc: 0.5764\n",
      "Epoch 4/50\n",
      " - 7s - loss: 0.6523 - acc: 0.6350 - val_loss: 0.6462 - val_acc: 0.6416\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.6480 - acc: 0.6445 - val_loss: 0.6340 - val_acc: 0.6662\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6437 - acc: 0.6475 - val_loss: 0.6681 - val_acc: 0.5875\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.6409 - acc: 0.6502 - val_loss: 0.6416 - val_acc: 0.6391\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6357 - acc: 0.6526 - val_loss: 0.6608 - val_acc: 0.5990\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.6350 - acc: 0.6451 - val_loss: 0.6212 - val_acc: 0.6876\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.6313 - acc: 0.6601 - val_loss: 0.6130 - val_acc: 0.6971\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.6331 - acc: 0.6591 - val_loss: 0.6151 - val_acc: 0.6977\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.6280 - acc: 0.6635 - val_loss: 0.6176 - val_acc: 0.6909\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.6244 - acc: 0.6626 - val_loss: 0.6076 - val_acc: 0.7016\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.6205 - acc: 0.6648 - val_loss: 0.6025 - val_acc: 0.6896\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6170 - acc: 0.6653 - val_loss: 0.6055 - val_acc: 0.7067\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.6167 - acc: 0.6559 - val_loss: 0.6010 - val_acc: 0.6945\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.6161 - acc: 0.6656 - val_loss: 0.5963 - val_acc: 0.6828\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.6122 - acc: 0.6623 - val_loss: 0.5947 - val_acc: 0.7032\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.6128 - acc: 0.6696 - val_loss: 0.6086 - val_acc: 0.6967\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.6115 - acc: 0.6691 - val_loss: 0.6262 - val_acc: 0.6716\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.6069 - acc: 0.6680 - val_loss: 0.5913 - val_acc: 0.7008\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.6060 - acc: 0.6632 - val_loss: 0.6156 - val_acc: 0.6788\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.6097 - acc: 0.6695 - val_loss: 0.6226 - val_acc: 0.6419\n",
      "Epoch 24/50\n",
      " - 11s - loss: 0.6089 - acc: 0.6716 - val_loss: 0.6084 - val_acc: 0.6985\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.6079 - acc: 0.6742 - val_loss: 0.5892 - val_acc: 0.6896\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.6032 - acc: 0.6725 - val_loss: 0.5918 - val_acc: 0.7026\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.6047 - acc: 0.6727 - val_loss: 0.6075 - val_acc: 0.6800\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.6010 - acc: 0.6757 - val_loss: 0.5862 - val_acc: 0.7052\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.6000 - acc: 0.6752 - val_loss: 0.5957 - val_acc: 0.6994\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.5995 - acc: 0.6741 - val_loss: 0.5926 - val_acc: 0.7012\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.6028 - acc: 0.6695 - val_loss: 0.5841 - val_acc: 0.6947\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.5942 - acc: 0.6697 - val_loss: 0.5830 - val_acc: 0.6993\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5994 - acc: 0.6720 - val_loss: 0.5802 - val_acc: 0.7067\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.5985 - acc: 0.6720 - val_loss: 0.5915 - val_acc: 0.7019\n",
      "Epoch 35/50\n",
      " - 10s - loss: 0.5970 - acc: 0.6713 - val_loss: 0.5867 - val_acc: 0.7017\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5972 - acc: 0.6724 - val_loss: 0.5815 - val_acc: 0.7078\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5951 - acc: 0.6698 - val_loss: 0.5779 - val_acc: 0.7021\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.5934 - acc: 0.6682 - val_loss: 0.5697 - val_acc: 0.6991\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5874 - acc: 0.6703 - val_loss: 0.5781 - val_acc: 0.7081\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5919 - acc: 0.6711 - val_loss: 0.5804 - val_acc: 0.6811\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5866 - acc: 0.6714 - val_loss: 0.5734 - val_acc: 0.6962\n",
      "Epoch 42/50\n",
      " - 9s - loss: 0.5929 - acc: 0.6726 - val_loss: 0.5868 - val_acc: 0.7041\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.5989 - acc: 0.6759 - val_loss: 0.5811 - val_acc: 0.6920\n",
      "Epoch 44/50\n",
      " - 9s - loss: 0.5946 - acc: 0.6717 - val_loss: 0.5825 - val_acc: 0.7037\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.6000 - acc: 0.6747 - val_loss: 0.5812 - val_acc: 0.7065\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.6021 - acc: 0.6749 - val_loss: 0.5854 - val_acc: 0.6951\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5933 - acc: 0.6720 - val_loss: 0.5706 - val_acc: 0.6934\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.5944 - acc: 0.6730 - val_loss: 0.5875 - val_acc: 0.6940\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.6031 - acc: 0.6765 - val_loss: 0.5797 - val_acc: 0.7045\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.5994 - acc: 0.6774 - val_loss: 0.5946 - val_acc: 0.7024\n",
      "451.5689576999998  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 9s - loss: 0.6894 - acc: 0.5694 - val_loss: 0.6770 - val_acc: 0.5575\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.6693 - acc: 0.5804 - val_loss: 0.6706 - val_acc: 0.6131\n",
      "Epoch 3/50\n",
      " - 9s - loss: 0.6464 - acc: 0.6207 - val_loss: 0.6427 - val_acc: 0.6032\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6421 - acc: 0.6241 - val_loss: 0.6873 - val_acc: 0.5863\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6387 - acc: 0.6331 - val_loss: 0.6805 - val_acc: 0.5769\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6333 - acc: 0.6365 - val_loss: 0.6550 - val_acc: 0.6630\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6309 - acc: 0.6438 - val_loss: 0.6285 - val_acc: 0.6415\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.6271 - acc: 0.6513 - val_loss: 0.6502 - val_acc: 0.6192\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.6201 - acc: 0.6524 - val_loss: 0.6385 - val_acc: 0.6522\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.6183 - acc: 0.6595 - val_loss: 0.6378 - val_acc: 0.6637\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.6193 - acc: 0.6575 - val_loss: 0.6351 - val_acc: 0.6370\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.6143 - acc: 0.6583 - val_loss: 0.6296 - val_acc: 0.6462\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.6119 - acc: 0.6564 - val_loss: 0.6134 - val_acc: 0.6731\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.6111 - acc: 0.6583 - val_loss: 0.5948 - val_acc: 0.6566\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6127 - acc: 0.6579 - val_loss: 0.5888 - val_acc: 0.7031\n",
      "Epoch 16/50\n",
      " - 9s - loss: 0.6141 - acc: 0.6573 - val_loss: 0.6169 - val_acc: 0.6551\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.6074 - acc: 0.6629 - val_loss: 0.6161 - val_acc: 0.6763\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.6069 - acc: 0.6622 - val_loss: 0.6228 - val_acc: 0.6857\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.6106 - acc: 0.6631 - val_loss: 0.6179 - val_acc: 0.6573\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.6058 - acc: 0.6657 - val_loss: 0.5960 - val_acc: 0.6912\n",
      "Epoch 21/50\n",
      " - 9s - loss: 0.5952 - acc: 0.6622 - val_loss: 0.5804 - val_acc: 0.6871\n",
      "Epoch 22/50\n",
      " - 9s - loss: 0.6037 - acc: 0.6595 - val_loss: 0.5903 - val_acc: 0.6956\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.6006 - acc: 0.6642 - val_loss: 0.5765 - val_acc: 0.7007\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.6027 - acc: 0.6628 - val_loss: 0.5815 - val_acc: 0.7056\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5982 - acc: 0.6672 - val_loss: 0.5908 - val_acc: 0.6960\n",
      "Epoch 26/50\n",
      " - 9s - loss: 0.5986 - acc: 0.6683 - val_loss: 0.5819 - val_acc: 0.7020\n",
      "Epoch 27/50\n",
      " - 9s - loss: 0.5961 - acc: 0.6704 - val_loss: 0.5731 - val_acc: 0.7014\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.5957 - acc: 0.6705 - val_loss: 0.5797 - val_acc: 0.7023\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5935 - acc: 0.6697 - val_loss: 0.5748 - val_acc: 0.6985\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.5990 - acc: 0.6722 - val_loss: 0.5768 - val_acc: 0.7038\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.5976 - acc: 0.6745 - val_loss: 0.5755 - val_acc: 0.7059\n",
      "Epoch 32/50\n",
      " - 9s - loss: 0.5989 - acc: 0.6744 - val_loss: 0.5809 - val_acc: 0.6962\n",
      "Epoch 33/50\n",
      " - 9s - loss: 0.6043 - acc: 0.6746 - val_loss: 0.5848 - val_acc: 0.6963\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.6071 - acc: 0.6722 - val_loss: 0.6136 - val_acc: 0.6836\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.6027 - acc: 0.6747 - val_loss: 0.5738 - val_acc: 0.7101\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.5952 - acc: 0.6757 - val_loss: 0.5736 - val_acc: 0.7085\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.5979 - acc: 0.6759 - val_loss: 0.5786 - val_acc: 0.7077\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5987 - acc: 0.6768 - val_loss: 0.5774 - val_acc: 0.7040\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5994 - acc: 0.6752 - val_loss: 0.5783 - val_acc: 0.7060\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5993 - acc: 0.6751 - val_loss: 0.5754 - val_acc: 0.7073\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.5960 - acc: 0.6784 - val_loss: 0.5718 - val_acc: 0.6962\n",
      "Epoch 42/50\n",
      " - 9s - loss: 0.6001 - acc: 0.6746 - val_loss: 0.5833 - val_acc: 0.7059\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.5987 - acc: 0.6752 - val_loss: 0.5747 - val_acc: 0.7039\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.5993 - acc: 0.6711 - val_loss: 0.5741 - val_acc: 0.7080\n",
      "Epoch 45/50\n",
      " - 9s - loss: 0.5940 - acc: 0.6739 - val_loss: 0.5707 - val_acc: 0.7054\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.5888 - acc: 0.6733 - val_loss: 0.5721 - val_acc: 0.7045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      " - 8s - loss: 0.5951 - acc: 0.6747 - val_loss: 0.5767 - val_acc: 0.7066\n",
      "Epoch 48/50\n",
      " - 9s - loss: 0.5929 - acc: 0.6753 - val_loss: 0.5719 - val_acc: 0.7010\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.5973 - acc: 0.6765 - val_loss: 0.5761 - val_acc: 0.7035\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.5971 - acc: 0.6759 - val_loss: 0.5736 - val_acc: 0.6998\n",
      "439.6647361  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 9s - loss: 0.6713 - acc: 0.6005 - val_loss: 0.6440 - val_acc: 0.6374\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.6428 - acc: 0.6230 - val_loss: 0.6309 - val_acc: 0.6192\n",
      "Epoch 3/50\n",
      " - 9s - loss: 0.6391 - acc: 0.6340 - val_loss: 0.6470 - val_acc: 0.5997\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6297 - acc: 0.6357 - val_loss: 0.6668 - val_acc: 0.5776\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6249 - acc: 0.6442 - val_loss: 0.6358 - val_acc: 0.6753\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6230 - acc: 0.6435 - val_loss: 0.6283 - val_acc: 0.6710\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6185 - acc: 0.6482 - val_loss: 0.6433 - val_acc: 0.5687\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.6153 - acc: 0.6502 - val_loss: 0.6439 - val_acc: 0.6409\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.6118 - acc: 0.6574 - val_loss: 0.6311 - val_acc: 0.6680\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.6083 - acc: 0.6615 - val_loss: 0.6034 - val_acc: 0.6965\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.6085 - acc: 0.6608 - val_loss: 0.6076 - val_acc: 0.6519\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.6052 - acc: 0.6610 - val_loss: 0.5998 - val_acc: 0.7025\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.6034 - acc: 0.6666 - val_loss: 0.6084 - val_acc: 0.6580\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.6038 - acc: 0.6633 - val_loss: 0.5887 - val_acc: 0.6982\n",
      "Epoch 15/50\n",
      " - 11s - loss: 0.6007 - acc: 0.6656 - val_loss: 0.6056 - val_acc: 0.6628\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.6009 - acc: 0.6709 - val_loss: 0.6231 - val_acc: 0.6661\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.6026 - acc: 0.6711 - val_loss: 0.6173 - val_acc: 0.6679\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.6075 - acc: 0.6649 - val_loss: 0.5960 - val_acc: 0.6994\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.6073 - acc: 0.6643 - val_loss: 0.6016 - val_acc: 0.6925\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.6013 - acc: 0.6713 - val_loss: 0.5806 - val_acc: 0.6944\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.5982 - acc: 0.6714 - val_loss: 0.5819 - val_acc: 0.6741\n",
      "Epoch 22/50\n",
      " - 9s - loss: 0.5943 - acc: 0.6734 - val_loss: 0.5720 - val_acc: 0.6868\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.5942 - acc: 0.6788 - val_loss: 0.5843 - val_acc: 0.6854\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5945 - acc: 0.6813 - val_loss: 0.5934 - val_acc: 0.7010\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.6009 - acc: 0.6784 - val_loss: 0.5968 - val_acc: 0.6983\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5932 - acc: 0.6803 - val_loss: 0.5779 - val_acc: 0.7091\n",
      "Epoch 27/50\n",
      " - 11s - loss: 0.5912 - acc: 0.6785 - val_loss: 0.5810 - val_acc: 0.6563\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.5900 - acc: 0.6760 - val_loss: 0.5853 - val_acc: 0.6850\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5961 - acc: 0.6776 - val_loss: 0.6053 - val_acc: 0.6915\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.5972 - acc: 0.6822 - val_loss: 0.5913 - val_acc: 0.7071\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.5890 - acc: 0.6839 - val_loss: 0.5776 - val_acc: 0.7057\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.5906 - acc: 0.6765 - val_loss: 0.5813 - val_acc: 0.6978\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5937 - acc: 0.6787 - val_loss: 0.5722 - val_acc: 0.7017\n",
      "Epoch 34/50\n",
      " - 9s - loss: 0.5908 - acc: 0.6766 - val_loss: 0.5832 - val_acc: 0.7057\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5916 - acc: 0.6774 - val_loss: 0.5815 - val_acc: 0.7083\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5863 - acc: 0.6830 - val_loss: 0.5722 - val_acc: 0.7001\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.5872 - acc: 0.6813 - val_loss: 0.5728 - val_acc: 0.7070\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.5903 - acc: 0.6817 - val_loss: 0.5744 - val_acc: 0.7088\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.5913 - acc: 0.6817 - val_loss: 0.5700 - val_acc: 0.7069\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.5929 - acc: 0.6839 - val_loss: 0.5858 - val_acc: 0.7055\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.5905 - acc: 0.6812 - val_loss: 0.5742 - val_acc: 0.7054\n",
      "Epoch 42/50\n",
      " - 9s - loss: 0.5843 - acc: 0.6771 - val_loss: 0.5687 - val_acc: 0.7074\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.5897 - acc: 0.6758 - val_loss: 0.5789 - val_acc: 0.7081\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.5943 - acc: 0.6743 - val_loss: 0.5712 - val_acc: 0.7093\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.5911 - acc: 0.6805 - val_loss: 0.5837 - val_acc: 0.7073\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.5877 - acc: 0.6825 - val_loss: 0.5769 - val_acc: 0.7094\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5882 - acc: 0.6839 - val_loss: 0.5782 - val_acc: 0.7073\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.5883 - acc: 0.6822 - val_loss: 0.5686 - val_acc: 0.7062\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.5867 - acc: 0.6790 - val_loss: 0.5738 - val_acc: 0.7069\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.5898 - acc: 0.6848 - val_loss: 0.5860 - val_acc: 0.7066\n",
      "474.44088920000013  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 10s - loss: 0.7017 - acc: 0.5446 - val_loss: 0.6516 - val_acc: 0.6073\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.6617 - acc: 0.5983 - val_loss: 0.6555 - val_acc: 0.5990\n",
      "Epoch 3/50\n",
      " - 9s - loss: 0.6592 - acc: 0.5990 - val_loss: 0.6481 - val_acc: 0.6071\n",
      "Epoch 4/50\n",
      " - 9s - loss: 0.6445 - acc: 0.6203 - val_loss: 0.7002 - val_acc: 0.5749\n",
      "Epoch 5/50\n",
      " - 9s - loss: 0.6440 - acc: 0.6243 - val_loss: 0.6922 - val_acc: 0.5970\n",
      "Epoch 6/50\n",
      " - 9s - loss: 0.6235 - acc: 0.6379 - val_loss: 0.6798 - val_acc: 0.5909\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6172 - acc: 0.6462 - val_loss: 0.6467 - val_acc: 0.6496\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.6116 - acc: 0.6526 - val_loss: 0.6168 - val_acc: 0.6752\n",
      "Epoch 9/50\n",
      " - 9s - loss: 0.6085 - acc: 0.6526 - val_loss: 0.6031 - val_acc: 0.6830\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.6016 - acc: 0.6595 - val_loss: 0.5770 - val_acc: 0.6968\n",
      "Epoch 11/50\n",
      " - 9s - loss: 0.5989 - acc: 0.6587 - val_loss: 0.5820 - val_acc: 0.7015\n",
      "Epoch 12/50\n",
      " - 9s - loss: 0.5978 - acc: 0.6602 - val_loss: 0.5912 - val_acc: 0.6724\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.5993 - acc: 0.6624 - val_loss: 0.6003 - val_acc: 0.6886\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.6026 - acc: 0.6608 - val_loss: 0.5937 - val_acc: 0.6955\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.6051 - acc: 0.6625 - val_loss: 0.6064 - val_acc: 0.6855\n",
      "Epoch 16/50\n",
      " - 9s - loss: 0.6000 - acc: 0.6670 - val_loss: 0.5996 - val_acc: 0.6997\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.5979 - acc: 0.6659 - val_loss: 0.5930 - val_acc: 0.6835\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.6009 - acc: 0.6656 - val_loss: 0.5968 - val_acc: 0.6891\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.6033 - acc: 0.6643 - val_loss: 0.5867 - val_acc: 0.7050\n",
      "Epoch 20/50\n",
      " - 9s - loss: 0.5936 - acc: 0.6680 - val_loss: 0.5823 - val_acc: 0.6985\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.5979 - acc: 0.6697 - val_loss: 0.6074 - val_acc: 0.6780\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.6029 - acc: 0.6700 - val_loss: 0.5879 - val_acc: 0.6964\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.6002 - acc: 0.6703 - val_loss: 0.5882 - val_acc: 0.7017\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.5974 - acc: 0.6688 - val_loss: 0.5858 - val_acc: 0.6985\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.5990 - acc: 0.6703 - val_loss: 0.5752 - val_acc: 0.6979\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.5976 - acc: 0.6722 - val_loss: 0.5838 - val_acc: 0.6990\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.5937 - acc: 0.6690 - val_loss: 0.5800 - val_acc: 0.7073\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.6000 - acc: 0.6707 - val_loss: 0.5910 - val_acc: 0.6761\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.5990 - acc: 0.6704 - val_loss: 0.5934 - val_acc: 0.7054\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.6009 - acc: 0.6729 - val_loss: 0.5972 - val_acc: 0.6932\n",
      "Epoch 31/50\n",
      " - 9s - loss: 0.6032 - acc: 0.6715 - val_loss: 0.5791 - val_acc: 0.7010\n",
      "Epoch 32/50\n",
      " - 8s - loss: 0.5990 - acc: 0.6720 - val_loss: 0.5818 - val_acc: 0.7003\n",
      "Epoch 33/50\n",
      " - 9s - loss: 0.5970 - acc: 0.6709 - val_loss: 0.5797 - val_acc: 0.7081\n",
      "Epoch 34/50\n",
      " - 9s - loss: 0.5994 - acc: 0.6727 - val_loss: 0.5754 - val_acc: 0.6947\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5977 - acc: 0.6696 - val_loss: 0.5796 - val_acc: 0.7037\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5969 - acc: 0.6679 - val_loss: 0.5929 - val_acc: 0.6966\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.6025 - acc: 0.6721 - val_loss: 0.5842 - val_acc: 0.6947\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5959 - acc: 0.6702 - val_loss: 0.5782 - val_acc: 0.6957\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5968 - acc: 0.6708 - val_loss: 0.5767 - val_acc: 0.7088\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5982 - acc: 0.6725 - val_loss: 0.5843 - val_acc: 0.6969\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5942 - acc: 0.6733 - val_loss: 0.5788 - val_acc: 0.7052\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.5902 - acc: 0.6727 - val_loss: 0.5832 - val_acc: 0.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      " - 9s - loss: 0.5892 - acc: 0.6729 - val_loss: 0.5734 - val_acc: 0.6957\n",
      "Epoch 44/50\n",
      " - 9s - loss: 0.5877 - acc: 0.6755 - val_loss: 0.5731 - val_acc: 0.7056\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.5916 - acc: 0.6722 - val_loss: 0.5884 - val_acc: 0.7015\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.6006 - acc: 0.6753 - val_loss: 0.5827 - val_acc: 0.7092\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.6033 - acc: 0.6760 - val_loss: 0.5796 - val_acc: 0.7068\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.5897 - acc: 0.6744 - val_loss: 0.5691 - val_acc: 0.7115\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.5938 - acc: 0.6736 - val_loss: 0.5947 - val_acc: 0.6991\n",
      "Epoch 50/50\n",
      " - 8s - loss: 0.6020 - acc: 0.6725 - val_loss: 0.5724 - val_acc: 0.7029\n",
      "461.83000730000003  seconds\n",
      "Train on 197754 samples, validate on 11430 samples\n",
      "Epoch 1/50\n",
      " - 10s - loss: 0.6937 - acc: 0.5517 - val_loss: 0.6703 - val_acc: 0.6107\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.6667 - acc: 0.5861 - val_loss: 0.6722 - val_acc: 0.6086\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.6595 - acc: 0.6019 - val_loss: 0.6517 - val_acc: 0.6311\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.6432 - acc: 0.6224 - val_loss: 0.6088 - val_acc: 0.6980\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.6366 - acc: 0.6346 - val_loss: 0.6141 - val_acc: 0.6262\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.6221 - acc: 0.6384 - val_loss: 0.6085 - val_acc: 0.6119\n",
      "Epoch 7/50\n",
      " - 9s - loss: 0.6114 - acc: 0.6449 - val_loss: 0.5945 - val_acc: 0.7064\n",
      "Epoch 8/50\n",
      " - 9s - loss: 0.6078 - acc: 0.6539 - val_loss: 0.6153 - val_acc: 0.6219\n",
      "Epoch 9/50\n",
      " - 10s - loss: 0.6036 - acc: 0.6573 - val_loss: 0.5847 - val_acc: 0.7088\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.6023 - acc: 0.6630 - val_loss: 0.5974 - val_acc: 0.7038\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.6030 - acc: 0.6568 - val_loss: 0.5821 - val_acc: 0.7054\n",
      "Epoch 12/50\n",
      " - 11s - loss: 0.6038 - acc: 0.6584 - val_loss: 0.6079 - val_acc: 0.6899\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.5977 - acc: 0.6659 - val_loss: 0.5932 - val_acc: 0.6611\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.5990 - acc: 0.6656 - val_loss: 0.5990 - val_acc: 0.7010\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.5993 - acc: 0.6684 - val_loss: 0.5858 - val_acc: 0.7088\n",
      "Epoch 16/50\n",
      " - 9s - loss: 0.6031 - acc: 0.6591 - val_loss: 0.5909 - val_acc: 0.6784\n",
      "Epoch 17/50\n",
      " - 9s - loss: 0.6021 - acc: 0.6621 - val_loss: 0.5912 - val_acc: 0.7049\n",
      "Epoch 18/50\n",
      " - 9s - loss: 0.6002 - acc: 0.6653 - val_loss: 0.6023 - val_acc: 0.6906\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.5997 - acc: 0.6685 - val_loss: 0.5832 - val_acc: 0.7014\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.5967 - acc: 0.6660 - val_loss: 0.5799 - val_acc: 0.6873\n",
      "Epoch 21/50\n",
      " - 9s - loss: 0.5979 - acc: 0.6659 - val_loss: 0.5810 - val_acc: 0.7071\n",
      "Epoch 22/50\n",
      " - 9s - loss: 0.5944 - acc: 0.6694 - val_loss: 0.5784 - val_acc: 0.7038\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.5893 - acc: 0.6711 - val_loss: 0.5805 - val_acc: 0.6893\n",
      "Epoch 24/50\n",
      " - 9s - loss: 0.5883 - acc: 0.6678 - val_loss: 0.5725 - val_acc: 0.6709\n",
      "Epoch 25/50\n",
      " - 9s - loss: 0.5918 - acc: 0.6688 - val_loss: 0.5747 - val_acc: 0.7057\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.6002 - acc: 0.6757 - val_loss: 0.5812 - val_acc: 0.7082\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.6037 - acc: 0.6730 - val_loss: 0.5893 - val_acc: 0.7066\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.6021 - acc: 0.6760 - val_loss: 0.5802 - val_acc: 0.7089\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.5959 - acc: 0.6692 - val_loss: 0.5780 - val_acc: 0.7086\n",
      "Epoch 30/50\n",
      " - 9s - loss: 0.5963 - acc: 0.6698 - val_loss: 0.5760 - val_acc: 0.7066\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.5977 - acc: 0.6733 - val_loss: 0.5781 - val_acc: 0.7068\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.5922 - acc: 0.6676 - val_loss: 0.5826 - val_acc: 0.7053\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.5956 - acc: 0.6731 - val_loss: 0.5831 - val_acc: 0.7101\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.5962 - acc: 0.6704 - val_loss: 0.5679 - val_acc: 0.7065\n",
      "Epoch 35/50\n",
      " - 9s - loss: 0.5885 - acc: 0.6683 - val_loss: 0.5736 - val_acc: 0.7028\n",
      "Epoch 36/50\n",
      " - 9s - loss: 0.5944 - acc: 0.6683 - val_loss: 0.5779 - val_acc: 0.7061\n",
      "Epoch 37/50\n",
      " - 9s - loss: 0.6055 - acc: 0.6746 - val_loss: 0.5933 - val_acc: 0.7083\n",
      "Epoch 38/50\n",
      " - 9s - loss: 0.5970 - acc: 0.6750 - val_loss: 0.5777 - val_acc: 0.7067\n",
      "Epoch 39/50\n",
      " - 9s - loss: 0.5985 - acc: 0.6745 - val_loss: 0.5956 - val_acc: 0.6964\n",
      "Epoch 40/50\n",
      " - 9s - loss: 0.5937 - acc: 0.6720 - val_loss: 0.5709 - val_acc: 0.6894\n",
      "Epoch 41/50\n",
      " - 9s - loss: 0.5916 - acc: 0.6726 - val_loss: 0.5871 - val_acc: 0.7038\n",
      "Epoch 42/50\n",
      " - 9s - loss: 0.5965 - acc: 0.6744 - val_loss: 0.5815 - val_acc: 0.7082\n",
      "Epoch 43/50\n",
      " - 9s - loss: 0.6100 - acc: 0.6743 - val_loss: 0.5983 - val_acc: 0.7018\n",
      "Epoch 44/50\n",
      " - 9s - loss: 0.6039 - acc: 0.6737 - val_loss: 0.5847 - val_acc: 0.6808\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.6095 - acc: 0.6755 - val_loss: 0.5930 - val_acc: 0.7058\n",
      "Epoch 46/50\n",
      " - 9s - loss: 0.6002 - acc: 0.6765 - val_loss: 0.5742 - val_acc: 0.7016\n",
      "Epoch 47/50\n",
      " - 9s - loss: 0.5882 - acc: 0.6741 - val_loss: 0.5693 - val_acc: 0.7077\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.5942 - acc: 0.6753 - val_loss: 0.5804 - val_acc: 0.7009\n",
      "Epoch 49/50\n",
      " - 9s - loss: 0.6029 - acc: 0.6757 - val_loss: 0.5856 - val_acc: 0.7072\n",
      "Epoch 50/50\n",
      " - 9s - loss: 0.6019 - acc: 0.6760 - val_loss: 0.5911 - val_acc: 0.7020\n",
      "465.27948840000045  seconds\n"
     ]
    }
   ],
   "source": [
    "model15 = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    hist = model.fit(xtrain, ytrain, epochs=50, batch_size=64, validation_data=(xtest15, ytest15), verbose=2)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    print(elapsed, \" seconds\")\n",
    "    model15.append(hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536.7866814000008  seconds\n",
      "548.6526052999998  seconds\n",
      "495.21724539999923  seconds\n",
      "453.9035316999998  seconds\n",
      "842.2444189999987  seconds\n"
     ]
    }
   ],
   "source": [
    "model20 = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    hist = model.fit(xtrain, ytrain, epochs=50, batch_size=64, validation_data=(xtest20, ytest20), verbose=0)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    print(elapsed, \" seconds\")\n",
    "    model20.append(hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506.567465600001  seconds\n",
      "534.8828474000002  seconds\n",
      "528.7611274999999  seconds\n",
      "560.3554899999999  seconds\n",
      "571.1706548999991  seconds\n"
     ]
    }
   ],
   "source": [
    "model25 = []\n",
    "for i in range(5):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(8,dropout=0.25,input_shape = (9,53)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    hist = model.fit(xtrain, ytrain, epochs=50, batch_size=64, validation_data=(xtest25, ytest25), verbose=0)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    print(elapsed, \" seconds\")\n",
    "    model25.append(hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:  0.5645669291338583\n",
      "10:  0.6379702537182852\n",
      "15:  0.6975503062117235\n",
      "20:  0.748665441498206\n",
      "25:  0.7947586693726286\n"
     ]
    }
   ],
   "source": [
    "print(\"5: \",sum([x[0] for x in np.around(model.predict(xtest5))]==ytest5)/len(ytest5))\n",
    "print(\"10: \",sum([x[0] for x in np.around(model.predict(xtest10))]==ytest10)/len(ytest10))\n",
    "print(\"15: \",sum([x[0] for x in np.around(model.predict(xtest15))]==ytest15)/len(ytest15))\n",
    "print(\"20: \",sum([x[0] for x in np.around(model.predict(xtest20))]==ytest20)/len(ytest20))\n",
    "print(\"25: \",sum([x[0] for x in np.around(model.predict(xtest25))]==ytest25)/len(ytest25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34290"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(model.predict(xtest15)))\n",
    "len(ytest15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4VFX6wPHvm8mEJJBCSAFSSIDQpUjoVbBgQezCWlFB1153ddef7rrN1S021NXVFSsiNlQUBcGCIL0X6SQEkgCpQPr5/XFnYEgmyUwyQ0h4P8+TJ5l7z733jDzOO+e8p4gxBqWUUqo2AY1dAaWUUqc+DRZKKaXqpMFCKaVUnTRYKKWUqpMGC6WUUnXSYKGUUqpOGiyU8gEReUNE/uxh2V0icnZD76PUyaTBQimlVJ00WCillKqTBgt12nB0/zwkImtF5LCIvCYicSLypYgUisg8EWntUv5iEdkgInkislBEuruc6yciKx3XvQ8EV3nWRSKy2nHtTyLSu551niIi20TkkIjMFpH2juMiIv8WkWwRyXe8p16OcxeIyEZH3faKyIP1+g+mlAsNFup0czlwDtAFGA98CfwOiMb6/+FuABHpArwH3AvEAHOAz0QkSESCgE+At4Ao4APHfXFceybwOnAr0Ab4DzBbRFp4U1ERGQP8DbgKaAfsBmY4Tp8LjHS8j0jgauCg49xrwK3GmDCgF/CtN89Vyh0NFup087wxJssYsxf4AfjZGLPKGFMCfAz0c5S7GvjCGPONMaYM+AcQAgwFBgN24BljTJkxZhawzOUZU4D/GGN+NsZUGGOmAyWO67xxDfC6MWalo36PAENEJBkoA8KAboAYYzYZY/Y5risDeohIuDEm1xiz0svnKlWNBgt1usly+fuom9etHH+3x/omD4AxphJIB+Id5/aaE1fh3O3ydwfgAUcXVJ6I5AGJjuu8UbUORVith3hjzLfAC8A0IEtEXhGRcEfRy4ELgN0i8p2IDPHyuUpVo8FCKfcysT70AStHgPWBvxfYB8Q7jjklufydDvzFGBPp8hNqjHmvgXVoidWttRfAGPOcMaY/0BOrO+ohx/FlxpgJQCxWd9lML5+rVDUaLJRybyZwoYiMFRE78ABWV9JPwGKgHLhbRAJF5DJgoMu1rwK3icggRyK6pYhcKCJhXtbhXWCyiPR15Dv+itVttktEBjjubwcOA8VAhSOnco2IRDi6zwqAigb8d1AK0GChlFvGmC3AtcDzwAGsZPh4Y0ypMaYUuAy4EcjFym985HLtcqy8xQuO89scZb2tw3zg/4APsVoznYCJjtPhWEEpF6ur6iBWXgXgOmCXiBQAtzneh1INIrr5kVJKqbpoy0IppVSdNFgopZSqkwYLpZRSddJgoZRSqk6BjV0BX4mOjjbJycmNXQ2llGpSVqxYccAYE1NXuWYTLJKTk1m+fHljV0MppZoUEdlddynthlJKKeUBDRZKKaXqpMFCKaVUnZpNzsKdsrIyMjIyKC4ubuyq+F1wcDAJCQnY7fbGropSqhlq1sEiIyODsLAwkpOTOXGB0ObFGMPBgwfJyMggJSWlsaujlGqGmnU3VHFxMW3atGnWgQJARGjTps1p0YJSSjWOZh0sgGYfKJxOl/eplGoczT5Y1KWispKsgmKOlJY3dlWUUuqUddoHC4CsgmIOl/hnf5i8vDxefPFFr6+74IILyMvL80ONlFLKe6d9sAgQIUCEsopKv9y/pmBRUVF7cJozZw6RkZF+qZNSSnmrWY+G8oSIYLcF+C1YPPzww2zfvp2+fftit9tp1aoV7dq1Y/Xq1WzcuJFLLrmE9PR0iouLueeee5g6dSpwfPmSoqIizj//fIYPH85PP/1EfHw8n376KSEhIX6pr1JKuePXYCEi44BnARvwX2PMk1XO/xs4y/EyFIg1xkQ6zt0APOo492djzPSG1OWPn21gY2aB23PFZRUYIMRu8+qePdqH8/j4nrWWefLJJ1m/fj2rV69m4cKFXHjhhaxfv/7YENfXX3+dqKgojh49yoABA7j88stp06bNCffYunUr7733Hq+++ipXXXUVH374IddeqztlKqVOHr8FCxGxAdOAc4AMYJmIzDbGbHSWMcbc51L+LqCf4+8o4HEgDTDACse1uX6qK5WVJ2d72YEDB54wF+K5557j448/BiA9PZ2tW7dWCxYpKSn07dsXgP79+7Nr166TUlellHLyZ8tiILDNGLMDQERmABOAjTWUn4QVIADOA74xxhxyXPsNMA54r76Vqa0FsD//KDmFpfSKD/f7ENSWLVse+3vhwoXMmzePxYsXExoayujRo93OlWjRosWxv202G0ePHvVrHZVSqip/JrjjgXSX1xmOY9WISAcgBfjW22t9wW4LwGAo90PrIiwsjMLCQrfn8vPzad26NaGhoWzevJklS5b4/PlKKeUL/mxZuPuKXtOn8URgljHGOUTIo2tFZCowFSApKak+dQSsYAFQVlF57G9fadOmDcOGDaNXr16EhIQQFxd37Ny4ceN4+eWX6d27N127dmXw4ME+fbZSSvmKP4NFBpDo8joByKyh7ETgjirXjq5y7cKqFxljXgFeAUhLS6t3s8Bus2JTWYV/8hbvvvuu2+MtWrTgyy+/dHvOmZeIjo5m/fr1x44/+OCDPq+fUkrVxZ/dUMuAVBFJEZEgrIAwu2ohEekKtAYWuxyeC5wrIq1FpDVwruOYXwS6tCyUUkpV57eWhTGmXETuxPqQtwGvG2M2iMgTwHJjjDNwTAJmGGOMy7WHRORPWAEH4AlnstsfAgME8ePEPKWUaur8Os/CGDMHmFPl2GNVXv+hhmtfB173W+VciAj2AKHcT91QSinV1J32y3042W0BlGrLQiml3NJg4WC3actCKaVqosHCwbk+lEvqRCmllIMGC4dAWwCVxlBxkpb9qEmrVq0a9flKKeWOBguHY3MtGjlYKKXUqei0X6LcyXUWt7erz9bmt7/9LR06dOD2228H4A9/+AMiwvfff09ubi5lZWX8+c9/ZsKECT57plJK+drpEyy+fBj2r6vxdIgxdCytoIU9AAI8bHC1PQPOf7LWIhMnTuTee+89FixmzpzJV199xX333Ud4eDgHDhxg8ODBXHzxxbqPtlLqlHX6BIs6OD+nfZ3f7tevH9nZ2WRmZpKTk0Pr1q1p164d9913H99//z0BAQHs3buXrKws2rZt69uHK6WUj5w+waKOFoAA6fsKCGsRSEJUqE8ffcUVVzBr1iz279/PxIkTeeedd8jJyWHFihXY7XaSk5PdLk2ulFKnitMnWHgg0CZ+SXBPnDiRKVOmcODAAb777jtmzpxJbGwsdrudBQsWsHv3bp8/UymlfEmDhQt7gH9mcffs2ZPCwkLi4+Np164d11xzDePHjyctLY2+ffvSrVs3nz9TKaV8SYOFC3tgAIdLy/1y73XrjifXo6OjWbx4sdtyRUVFfnm+Uko1hM6zcGG3CRWVjT8xTymlTjUaLFw451qU64KCSil1gmYfLLxZ68ke4Nwxr+kFC13TSinlT806WAQHB3Pw4EGPP0iPz+JuWh+8xhgOHjxIcHBwY1dFKdVMNesEd0JCAhkZGeTk5HhU3hhDVl4xxTmBhAXb/Vw73woODiYhIaGxq6GUaqaadbCw2+2kpKR4dc2kP37NxX3a86dLuvupVkop1fQ0626o+mgXEcz+Ap1NrZRSrjRYVNE2Ipj9+RoslFLKlQaLKtqGB7NPg4VSSp3Ar8FCRMaJyBYR2SYiD9dQ5ioR2SgiG0TkXZfjTzmObRKR5+Qkrd/dNiKYg4dLKC1vesNnlVLKX/yW4BYRGzANOAfIAJaJyGxjzEaXMqnAI8AwY0yuiMQ6jg8FhgG9HUV/BEYBC/1VX6e24cEYA9mFxSS09u3qs0op1VT5s2UxENhmjNlhjCkFZgBVt4ObAkwzxuQCGGOyHccNEAwEAS0AO5Dlx7oe0zbCmqugeQullDrOn8EiHkh3eZ3hOOaqC9BFRBaJyBIRGQdgjFkMLAD2OX7mGmM2VX2AiEwVkeUistzTuRR1aRcRAqAjopRSyoU/g4W7HEPVqdGBQCowGpgE/FdEIkWkM9AdSMAKMGNEZGS1mxnzijEmzRiTFhMT45NKtw3XloVSSlXlz2CRASS6vE4AMt2U+dQYU2aM2QlswQoelwJLjDFFxpgi4EtgsB/rekx4SCAhdpuOiFJKKRf+DBbLgFQRSRGRIGAiMLtKmU+AswBEJBqrW2oHsAcYJSKBImLHSm5X64byBxHRiXlKKVWF34KFMaYcuBOYi/VBP9MYs0FEnhCRix3F5gIHRWQjVo7iIWPMQWAWsB1YB6wB1hhjPvNXXauKC9eJeUop5cqva0MZY+YAc6oce8zlbwPc7/hxLVMB3OrPutWmXUQwP+881FiPV0qpU47O4HYjLiKYrIJiKnXHPKWUAjRYuNUuIpjySsOBwyWNXRWllDolaLBwQ4fPKqXUiTRYuKGzuJVS6kQaLNw4Fix0+KxSSgEaLNyKbtmCwADRiXlKKeWgwcKNgAAhLjyYLA0WSikFaLCoUdsI3QRJKaWcNFjUoK0u+aGUUsdosKhBW8eSH9Ykc6WUOr1psKhBu4hgjpZVUHC0vLGropRSjU6DRQ3iHBPz9hUcbeSaKKVU49NgUYN2OjFPKaWO0WBRA53FrZRSx2mwqEFsmKMbSoOFUkppsKhJUGAAMWEt+HBlBm8t2U1BcVljV0kppRqNBotaPHFxT8KD7fzfJ+sZ9Jf5/GbWGlbtydXhtEqp0440lw++tLQ0s3z5cp/f1xjD2ox83lu6h9lrMjlSWkG3tmHcOaYzF/Vu7/PnKaXUySQiK4wxaXWV8+u2qs2BiNAnMZI+iZH8/sLuzF6TyVuLd3PXe6toEWjjnB5xjV1FpZTyO+2G8kJYsJ1rBnXgkzuG0Ts+gntmrGJDZn5jV0sppfzOr8FCRMaJyBYR2SYiD9dQ5ioR2SgiG0TkXZfjSSLytYhscpxP9mddvRFst/Hq9WlEhNiZMn052bqGlFKqmfNbsBARGzANOB/oAUwSkR5VyqQCjwDDjDE9gXtdTr8JPG2M6Q4MBLL9Vdf6iA0P5r83pJF3tIwpb62guKyisauklFJ+48+WxUBgmzFmhzGmFJgBTKhSZgowzRiTC2CMyQZwBJVAY8w3juNFxpgjfqxrvfRsH8EzV/dlbUYeD36wRkdJKaWaLX8Gi3gg3eV1huOYqy5AFxFZJCJLRGScy/E8EflIRFaJyNOOlsop59yebfntuG58vnYfz8zb2tjVUUopv/DnaChxc6zqV+9AIBUYDSQAP4hIL8fxEUA/YA/wPnAj8NoJDxCZCkwFSEpK8l3NvXTryI5szy7i2flb6RTbiov76JBapVTz4s+WRQaQ6PI6Ach0U+ZTY0yZMWYnsAUreGQAqxxdWOXAJ8CZVR9gjHnFGJNmjEmLiYnxy5vwhIjwl0vPYGBKFA99sIadBw43Wl2UUsof/BkslgGpIpIiIkHARGB2lTKfAGcBiEg0VvfTDse1rUXEGQHGABv9WFfvbJ0HK9444VBQYAAvTOpHkC2Axz5dr/kLpVSz4rdg4WgR3AnMBTYBM40xG0TkCRG52FFsLnBQRDYCC4CHjDEHjTEVwIPAfBFZh9Wl9aq/6uoVY+Cr38Ln90PurhNOxYYH89C4rvyw9QCz11RtRCmlVNOly314K3MVvDLa8dCb4aJ/nXC6otJw2YuL2JtXzPwHRhERYvd/nZRSqp48Xe5DZ3B7a90sCLBDjwmw6m0o3H/CaVuAlb84dLiEf8zd0kiVVEop39Jg4Y3KClj/IaSeC2Mfh8oyWDytWrFe8RHcMDSZt3/ezer0vBpvZ4xhyY6DHC7Rfb6VUqc2DRbe2L0ICvfBGVdAm07Q8zJY/jocza1W9P5zuhAb1oLffbSO8orKaudzCkuY8uYKJr6yhOfm6/wMpdSpTYOFN9Z9AEGtoItj7uDw+6C0CJZWz72HBdt5fHxPNu4rYPri3Secm7thP+Oe+Z7vt+YQHxnCNxuzTkbtlVKq3jRYeKq8BDZ+Ct0ugqBQ61jbXlbgWPISlFafW3F+r7ac1TWGf329hX35RykoLuOBmWu49a0VtI0I5vO7hjN1ZEd2HDjM9pyik/yGlFLKcxosPLVtHhTnwxlXnnh8xANw9BCsmF7tEhHhiQm9KK803PPeas5/5gc+XpXBXWM68/Htw+gSF8bY7rEAzN+krQul1KlLg4Wn1n0AodHQcdSJxxMHQvII+Ol5q/VRRWJUKHePTWXprkPYbcKsXw/lgXO7EhRo/adPaB1Kt7ZhzNt0Si2qq5RSJ9Bg4YniAtjyJfS8FGxu5k0Mvw8KM2HNDLeX3zqyI/+5rj9z7hnBmUmtq50/u3scK3bnknu41Nc1V0opn9Bg4YnNX0B5cfUuKKdOY6BdX1j0jDW8topAWwDn9WxLaJD7dRvHdo+lotKw8BdtXSilTk0aLDyx7gOITLK6nNwRsXIXh3bAxk+8vn2fhEiiW7XQriil1ClLg0VdirJhx0LodYUVFGrS7SKI7gI//MtaP8oLAQHC2G6xfL8lh9Ly6nMylFKqsWmwqMuGT8BU1NwF5RQQAAOnQtZ6q4XhpbHdYyksKWfpzkP1rKhSSvmPBou6rPsA4npBXI+6y3YYZv3OWOb1Y4anRtMiMIB5OoRWKXUK0mBRm0M7IWOptbyHJ2K6QlBYvYJFaFAgwzpHM39zlu6FoZQ65WiwqM36D63fvS73rHyADeLPhPSl9Xrc2O6xpB86ytZsnc2tlDq1aLCozfqPIHGwNRLKU4kDIWuD2+U/6jK2WxyArhWllDrlaLCoSV46ZG+A7uO9uy5hgJUQz1zt9SPbRgRzRnyELv2hlDrlaLCoybZvrN+p53h3Xbxjw6l65C3A6opalZ7HgaLqS4copVRj0WBRk63zICLJmjvhjZZtIKpjvYPF2d3jMAYWbNYJekqpU4cGC3fKS2Hnd5B6du0T8WqSMNAKFvUY1dSzfThtw4N1CK1S6pSiwcKdPYutTY06e9kF5ZSQBkVZkJ/u9aUiwtjusazfuoPiQp2gp5Q6Nfg1WIjIOBHZIiLbROThGspcJSIbRWSDiLxb5Vy4iOwVkRf8Wc9qtn4NtiBIGVm/6xMGWL/rOYT27O5xPM/fKZoxpX7PV0opH/MoWIjIPY4PbhGR10RkpYicW8c1NmAacD7QA5gkIj2qlEkFHgGGGWN6AvdWuc2fgO88fC++s20eJA2BFq3qd31cLwgMgYzl9bp8SMcouko6rTJ/ZN1uzV0opRqfpy2Lm4wxBcC5QAwwGXiyjmsGAtuMMTuMMaXADGBClTJTgGnGmFwAY8yxT0YR6Q/EAV97WEffyEuHnM2QWmssrJ0t0JqcV88kd3DJQVpKCcGmmD++/BaXTFvEx6syKCmvvvy5UkqdDJ4GC2eW9wLgf8aYNS7HahIPuHbaZziOueoCdBGRRSKyRETGAYhIAPBP4KFaKyUyVUSWi8jynJwcD99KHeo7ZLaqhDTYtwbKir2/NnfnsT9/3z2HgqNl3Pf+Gob+7Vv+Mdfaz1sppU4mT4PFChH5GitYzBWRMKCutbTdBZOqw4MCgVRgNDAJ+K+IRAK3A3OMMbVmiI0xrxhj0owxaTExMR68DQ/Ud8hsVQkDobIM9q/1/trcXdbvkCj6Vaxl3v2jeOvmgZzZoTUvLtzGqKcX8uSXmykoLjt+TcYKmD4eyjSQKKV8z/3WbdXdDPQFdhhjjohIFFZXVG0ygESX1wlAppsyS4wxZcBOEdmCFTyGACNE5HagFRAkIkXGGLdJcp9xDpntfVX9hsy6SnCZnFfTpkk1ObQTEKsey14joPwII1JjGJEaQ/qhIzwzbysvf7edmcvTue/sVCYNTCJw2auw83s48Au069OwuiulVBWetiyGAFuMMXkici3wKJBfxzXLgFQRSRGRIGAiMLtKmU+AswBEJBqrW2qHMeYaY0ySMSYZeBB40++BAho+ZNZVWFurhVKfvEXuTohIsOpRWQZ7lhw7lRgVyj+v6sPndw2nS1wr/u/TDVzw728p2/iFVSA/o+F1V0qpKjwNFi8BR0SkD/AbYDfwZm0XGGPKgTuBucAmYKYxZoOIPCEiFzuKzQUOishGYAHwkDHmYD3eh29s+6ZhQ2arSkiD9PoEi13QOhk6DIGAQKu1U0Wv+AjemzKYV69Po3f5euxlBQCUH9rTsDorpZQbngaLcmNtsjABeNYY8ywQVtdFxpg5xpguxphOxpi/OI49ZoyZ7fjbGGPuN8b0MMacYYyZ4eYebxhj7vT8LTXA1gYOma0qcSAUZEBB1d63OhzaCVEpENTSmrOx83u3xUSEc3rE8feeuykLCKbY2Nm35xcfVFwppU7kabAoFJFHgOuALxxzKOz+q1YjyM+AnE0NHwXlyjk5z5v5FiVFcDjbalkApIyyVrA9muu+fGUlti1zCEg9m0xiKNjv/ZauSilVF0+DxdVACdZ8i/1YQ2Cf9lutGsNWx5BZX+QrnNqeYXVrZXgxk9s5Eqp1ivW74yjAwK4f3ZffuxyK9mPrOYGjoe2R/AzdaU8p5XMeBQtHgHgHiBCRi4BiY0ytOYsmZ+s3VkI6pqvv7hnYAtr19a5l4QwWUY5gEZ8G9tAau6LY9BkE2CH1XIKjOxBTmc3m/YUNqrZSSlXl6XIfVwFLgSuBq4CfRcTDjambgIauMlubhAGQuQoqyuouC8cn5Dm7oQKDrDzKDjernhhjBYuUkRASSVxiZ2KkgIXrd/uk6kop5eRpN9TvgQHGmBuMMddjLeXxf/6r1knmyyGzVSWkQXkx7F/nWflDOyE4EkJaHz+WMhIObIHC/SeWzd5oBRfHbn6t4joCsG7jRl/UXCmljvE0WAS4rtsEHPTi2lOfr4fMuvI2yZ2783gXlFPHUdbvql1Rmz4DBLpdaL2OsOZAFmbtJKdQd9pTSvmOpx/4X4nIXBG5UURuBL4A5vivWieZr4fMuopIgLB2nk/Oy911PLnt1La31dqo2hW16XNIGgytYq3XkVawaC8HWLBFV6tVSvmOpwnuh4BXgN5AH+AVY8xv/Vmxk8YfQ2ZdiVhdUZ6MiKooh7w9x/MVTgE2SB5u5VWcI50O7YSsddDtouPlwtphJIBuwbnM1532lFI+5OnaUBhjPgQ+9GNdGkertjD5q+of0L6UMMDqMirKgVa1LHhYkAGV5dW7oQA6jobNnzu6qTpafwN0dwkWNjsS1p6+tkKe3nqA4rIKgu02X74TpdRpqtaWhYgUikiBm59CESk4WZX0K1ugtaxGeDv/PSPBsZBgXV1RVedYuHLmU5x5i02fWd1TVYNcZCLJgbkcKa1gyY7GWzlFKdW81BosjDFhxphwNz9hxpjwk1XJJq99X2uNp7q6og5VGTbrKrqL1Qra8Z01Kip96bFRUCeISCCidD8hdhvzN2neQinlG81nRNOpzB5izeaua1HB3J3WqKzw9tXPiVijonZ+7+iCMjUEi0QCCjMZ0bk18zdl6WxupZRPaLA4WRIGQuZKK4ldk0M7IbKDldB2J2UkHDkAi56DqE4Q0616mchEqCznohQhM7+YTft0NrdSquE0WJwsiQOh7Ahkra+5TO4u98ltJ2feIm+31apwN9s8IgmAEbHWdq7fbtZRUUqphtNgcbIcm5xXQ1eUMcf3sahJZNLx5Le7Liiw5nUArUuz6JMQwTzNWyilfECDxckSmQSt4qzEtDtHDkFJgfuRUK66XwRtUqH9mTU8x7GTbf4exnaPY01Gns7mVko1mAaLk0XEal3UNCKq6mqzNTn7j/DrRRBQwz9dUEsIiYL8DMZ2j8UYWLBZWxdKqYbRYHEyJQ60gkJRTvVzVVebrUmAzVr6vDaRiZCXTo924bSPCGaezuZWSjWQBouT6djkPDeti9rmWHgrIhHy0xERxnSP5QfHbG6llKovDRYnk3Nynru8Re5Oa8FBe0jDnxNhtSwwhrHd4zhaVsH7y9Ibfl+l1GlLg8XJZA+xluhwNyKqrpFQ3ohMhLLDcDSXEZ2jGdUlhj98toHZazJ9c3+l1GnHr8FCRMaJyBYR2SYiD9dQ5ioR2SgiG0TkXcexviKy2HFsrYhc7c96nlSJA2Hvyuo75x3aWfdIKE9FOEdEpRNoC+Dla/szIDmK+99fzTcbNX+hlPKe34KFiNiAacD5QA9gkoj0qFImFXgEGGaM6Qnc6zh1BLjecWwc8IyIRPqrridVwgAoP3ri5Lyyo1CYWfdIKE855lqQZ3U9hQTZeP3GAfSMj+COd1by49YDvnmOUuq04c+WxUBgmzFmhzGmFJgBTKhSZgowzRiTC+Dcjc8Y84sxZqvj70wgG6hlbe8mJNGR5HZdJyrXsWe2r1oWkdYsbvKP5ylatQhk+uQBdIxpyZQ3l7N81yHfPEspdVrwZ7CIB1yzqhmOY666AF1EZJGILBGRcVVvIiIDgSBgu5tzU0VkuYgsz8lxMxz1VBSRaK0e6zoi6tjS5Mm+eUZoGwgMsTZ2chEZGsRbNw+iXUQwk/+3jPV7833zPKVUs+fPYOFm4SKqLoEaCKQCo4FJwH9du5tEpB3wFjDZGFNZ7WbGvGKMSTPGpMXENJGGhwgkDjhxRJRzjoWvuqFErK6ovD3VTsWEteDtWwYRHmLnutd+ZtO+RtqWpLLS+lFKNQn+DBYZQKLL6wSg6nCcDOBTY0yZMWYnsAUreCAi4Vh7fT9qjFnix3qefAkDrcUAixwzqw/thKAwq0XgK5GJJ3RDuWofGcI7twwiKDCAK176ia837Pfdcz2x60f4Z1f47smT+1ylVL35M1gsA1JFJEVEgoCJwOwqZT4BzgIQkWisbqkdjvIfA28aYz7wYx0bx7G8haN14Rw2624V2fpyzrWoQXJ0Sz69YzidY1sx9a0VPDtvK5WVft77whhY9l94cwIczoZ1s/z7PKWUz/gtWBhjyoE7gbnAJmCmMWaDiDwhIhc7is0FDorIRmAB8JAx5iBwFTASuFFEVjt++vqrriddu74QYD+et8jdCVHJvn1GZKK190XZ0RqLtI0I5v1bh3DZmfH8e94v3P7OSg6X1Lxle9zXAAAgAElEQVTfRlZBMbsPHq5ffcpL4fN74YsHoNNYOOtROLT9+Mx1pdQpLdCfNzfGzAHmVDn2mMvfBrjf8eNa5m3gbX/WrVHZg6Fdb2tEVGWlNRqqS7XcfsMcm2uRAdGpNRYLttv455V96Nk+gr98sZHLXjzMq9enkdQmlMpKw5qMPBZszubbLdms31tAaJCNRb8dQ+uWQZ7XpSgb3r8O0pfA8PthzKNWkFjwZ9g+H6JuaeCbVUr5m87gbiwJAyFzlZW7qCjxXXLbyRks3CS5qxIRbh6ewps3DWJ/QTHjX/iRe2esYsBf5nHpiz/xwoJthNht3DaqE0dKK3hvWd33PCZzNbxyFuxbA1e8Dmc/bi2G2KaTtSvgtvn1fINKqZPJry0LVYvEAfDzS479tPHdsFmnSJeWhYeGp0Yz+85h3P7OShZsyWF01xjGdItlZGrMsZbEur15vLV4N1NGdMRuq+O7Rv5e+N/5VuL+5rnQrs/xcyLQeSysnWl1UQV60VJRSp10Giwai3MF2rUzrd++mpDnFNYeJKDGEVE16dCmJV/cPQJjDOIm4T55aAq3vLmcr9bvZ3yf9rXfbNVb1lay1/9otSSq6nw2LH8d0n+GlBFe1VMpdXJpN1RjiUiwVpndvxbEdrzbyFdsgVbAqGVEVG3cBQqAMd1i6dAmlP8tqiMxXVkBK9+Cjme5DxQAySOsVXi3zatXHZVSJ48Gi8bi3DkPrC4jmx8aebXMtaivgADhxqHJrNyTx+r0vJoLbv8WCjKg/w01lwkOh8TBVpJbKXVK02DRmJzzLXzdBeUU4ftgAXBlWiJhLQJrb12seANCo6HrhbXfrPMY2L8OCnU1XKVOZRosGpMzb+HrkVBOkYlQkGl1CflQqxaBXDUgkS/W7mN/fnH1AoVZ8MtX0HdS3Ynrzmdbv7d/69M6KqV8S4NFY2rXx1ohNmmIf+4fkQCV5VC4z+e3vmFIMhXG8NaSXdVPrnnXeu6ZtXRBOcWdAS1jNG+h1ClOg0VjsgfDveug91X+uX+EY6nyeia5a5PUJpRzusfx7s97Ttzf2xhY+SZ0GFbrZMBjAgKsGd3bv/V5C0gp5TsaLJqzesy18MZNw1PIPVLGJ6v2Hj+46wc4tMOzVoVT57Fw9BDsW+37SiqlfEKDRXPm3DEv34sZ114YlBJF93bh/G/RLqyVW4AV0yE4AnpcXPvFrjqNAQS2ad5CqVOVBovmLKglhET5pRsKrLkYNw1LZktWIT9tPwhHDsGm2dB7IthDPL9Ry2grf6N5C6VOWRosmrva5lrk/AKlRxp0+/F92tOmZZA1jHbNDKgorX1uRU06nw0Zy+BoDXM3Du2EzXPcn1NK+Z0Gi+YuIrF6zqKkCD6/H6YNgC8fatDtg+02rhncgfmbszi8+DWIT4O4nt7fqPNYMBWw87vq5zJWwKtjYMYkKGoi2+cq1cxosGjunJsgOXMKO7+Hl4ZYazJFd4E170Nhw3bKu3l4CpdHZ9KyYBub4y+r300SBkCL8Oqr0G6bB9MvwhjHSKm9yxtUV6VU/WiwaO4iE6HssNW6+OJBmD7eWo/ppq9g0gxrPsSy/zboEREhdv7SYQVHCGHiovYs2JLt/U1sdkgZaQULZ2BbOxPevRoT1ZFHY1+kzNh476MPeWnhdjLzat7USSnlexosmjvnAoX/GWkFhcG3w22LIGmwtcBf1wtg2Wu17qhXp+J8Wmz+FFufK0loG82tb65gweZ6BIzOZ1vrSeVsgcUvwkdTIHEwzyc9xzu/CFkhnehRuZW/f7WZoU9+y1X/Wcy7P+8h/0hZ/euulPKIBovmzrnia3AETJ4D4/4GQaHHzw+5w5rjsGZG/e5fWWnlP8qP0mLQTbxz82C6tg3j1rdW8O1mL9d76jzW+v3hLTD3Eeg+ns96P8+/ftjPxAGJxPcaSR/ZzncPjOD+c7pwoKiE3328jiFPzmfTvoL61V8p5RENFs1dXE+Y/CX8ehF0GFr9fIeh1p7gS160Pvi9YYyVIF8/C87+A7TvR0SonbdvHkS3dmHc9tZK5m/yImBEJll5lKx10P9GVg16hgc+3sKglCiemNALSRwApYV0qMzg7rGpzL9/FLPvHIYtQHh23lbv6q6U8ooGi9NBh6HWnAt3RGDInXDgF+/nOSz4q9W1NfRuGH7fscMRoXbecgaMt1cwbcE2jpSWe3bP8/4GFz1D5vC/MeXt1bQND+ala/sTFBhgjbSCY0luEaF3QiSTh6Xw1Yb9bN6vrQul/MWvwUJExonIFhHZJiIP11DmKhHZKCIbRORdl+M3iMhWx089Bu4rj/W8xNooafELnl+z5CX4/inodx2c80S10xEhVsAY3TWWp+duYeRTC5n+0y5KyutY/yn1bI70vo5b3lxBcVkF/70hjSjHlq606QTBkdZ8DBc3DUumZZCNF77d5nn9lVJe8VuwEBEbMA04H+gBTBKRHlXKpAKPAMOMMT2Bex3Ho4DHgUHAQOBxEWntr7qe9mx2GHSrNcdh/7q6y69+D756GLqPh4uesVonbkSE2Hn1+jQ+/PUQOsW05PHZGxjzj+/4YHk65RXuu7wqKw33v7+GzfsLeH5SP7rEhR0/KQIJada8CxeRoUHcMDSZL9btY1t2ocdvWynlOX/uwT0Q2GaM2QEgIjOACcBGlzJTgGnGmFwAY4xzCM15wDfGmEOOa78BxgHv+bG+p7f+N8B3T1mjkC59qeZym+fAp3dAyii4/DWPdvjr3yGKGVMH8+O2Azw9dwsPzVrLy99tZ1DHNpSUVVJaUUlJWQWlFZXkHi5lTUY+j17YnbO6xVa/WcIAWPgklBRCi+OB5JYRHXnjp11MW7Cdf1/dtz7/BZRStfBnN1Q84LrORIbjmKsuQBcRWSQiS0RknBfXIiJTRWS5iCzPydGZvQ0S0hr6XQvrPnA/Sc8YWDcLPrjRWsdp4jsQ2MLj24sII1Jj+PSOYbx8bX+C7Ta+3pDFkh0HWb83n90Hj3DocCl2WwD3nd2Fm4fXsCFUQhpgYO/KEw5HtQzi2sEd+HT1XnYeOOz5+1ZKecSfLQt3fRPGzfNTgdFAAvCDiPTy8FqMMa8ArwCkpaVVO6+8NPg2WPoKLH0Vxv6fdcwYa6+J+U9YS4i37Q3XfnjCt3pviAjjerVlXK+29atjfH/r997l0HHUCaemjOjI9J92MW3BNv5xZZ/63V8p5ZY/WxYZQKLL6wQg002ZT40xZcaYncAWrODhybXK16I6QrcLYflr1gKD6UvhjYvg7cusFWUveQmmLoTQqMarY0hraJMKGdWX/YgJa8GvBiXx8aq9pB9q2AKJSqkT+TNYLANSRSRFRIKAicDsKmU+Ac4CEJForG6pHcBc4FwRae1IbJ/rOKb8bcgdcDQXXj0LXjvHGlJ7/tNw13Lo+ysIsDV2DR1J7mXHlwVxcduoTtgChBcX6sgopXzJb8HCGFMO3In1Ib8JmGmM2SAiT4iIc2ecucBBEdkILAAeMsYcdCS2/4QVcJYBTziT3crPkoZA4iBr3+6xj8E9q2HQVK/yE36XkAaHcyCv+qZOceHBXJ2WyKwVGezV9aOU8hkxbr6dNUVpaWlm+XJdkdQnnHtcuC4LcirZt8Za6+ry1+CMK6qd3pt3lNFPL2DigCT+dEmvRqigatJKCuGLB6z5Q2H1zK05FJWUszf3KF3iWiE1DDH3RFZBMc9/u5XU2DCuGZREoM133/NFZIUxJq2ucv5McKum6lQNEk6xPSEwBPaucBss4iNDuKJ/Au8vS6dzbCuKSsrJPVxK7pEy8o6Ukne0jBGp0dw1JhVbQP3/B1bN1K4fYe37Vis7bXK9b1NWUcmNry9l+e5cusaFcWVaApf0iye6leet9LKKSqb/tItn5m3lSGk5lQZmLk/nT5f04sykkzv1TIOFanpsgdC+X7WZ3K5uH92ZD1fu5fHZGwAIsdtoHWonMjQIe2AAz8zbyvJduTw7sS9tvPif11+MMZSUVxJsPwVyQk3Ugi3ZRIUG0ScxsmE3yt544u96evLLzSzfncvkYcmsTs/jz19s4skvNzO2eyxX9k9kdNeYWlsIS3ce4rFP17N5fyGju8bwh/E92bivgCc+28hlL/7EpIGJ/Oa8brR2rnDgZxosVNOU0B9+/g+Ul7jNpyRGhbLot2OoqDREhtqrfQjPXJ7Oo5+sZ/zzP/LStf0b/gHTABsy83nog7VszS5kVJcYJvSN5+zucYQEaeDw1Mxl6fzmw7UEBQbwn+v6c1ZXNxM6PZW96cTf9TBn3T5e+3EnNwzpwOPjrZ0jt2YV8sGKDD5amcHcDVm0DrXTJS6MjjGt6BTTko4xLUmJbkWI3cZTX23mo1V7iY8M4ZXr+nNOjzhEhOTolozsEsOz837h9UW7+Gr9fh45vztX9E8gwM+tZM1ZqKZp46cw83q45VsrcNTDuox8bnt7BTmFJfxxQk8mDUzy6vrC4jLWpOfTJzGCsGC7188vLa/khW+38uLC7USGBjGuVxzfbMwiq6CE0CAb5/Vsy4S+7RneOdqnfdTNzSer9nLfzNUM7xxN7pFStuwv5PlJZ9Z/Ls9LwyBrPYREwW921LicTU125BRx8QuL6Bzbipm3DrEWwXRRVlHJwi05fL1hP9tzithx4DB5VfZkCbIFMHVkR+44q3ONXxo27y/g0Y/Xs3x3LsM6t+GtmwbVK2B4mrPQYKGapoJM+Fd3GPd3azJhPeUeLuXuGav4YesBrk5L5I8TetbaFVRSXsF3W3L4dHUm8zZlUVJeSYjdxoW92zFpYCJnJrX2KJG5NiOPhz5Yy5asQi7rF89j43sQGRpERaVh6c5DzF6zly/W7qOguJx2EcHMvHUIiVGneC6pEXyxdh93vbeSQSlteP3GAZRWVHLj/5ayNiOff1/dl4v7tPfuhhVl8Nf2YA+B4nx4YItXSe4jpeVcOu0nsguL+fzuEcRHhnh0Xe7hUnYcKGJHzmH25xdzYe92dIxpVed1lZWGD1dmUFBcXvOqB3XQYKGav392h+RhcHnDtoWtqDT8+5tfeGHBNqJbBdExuhUJrUOsn6hQElqHWHs8rc1kzjrrA7xNyyAu6t2OoZ2jWbglm9mrMzlcWkFqbCuuHpDI5WcmuO1LLi6r4Ln5W/nP9zuIbhXEXy89g7Hd49zWq6S8ggWbc3jogzV0bRvGjKmDm2wLY9aKDLIKirl9dKcGjQpy9fWG/dz+zkr6JkYy/aaBtGxh9aoXlZRz0xvLWL7rEE9d0Ycr+id4ftPszfDiIGvpm1Vvw3UfQ6cxx06nHzpCWHAgkaHV/22NMTwwcw0fr97L9MkDGdklpsHv8WTQ0VCq+XNOzmsgW4Dw4HldSUtuzew1mWTkHmXJjoPsKyg+Yd5fS0fX0MV92zOsczR2xwf3eT3b8vsLe/DF2kzeW5rOn7/YxN+/2kxEiJ2yCkN5RSVlldbvSsf9ruyfwKMX9SAipObuqxaBNsb1aktJeQX3zFjNtAXbuefs1Aa/35Ptx60H+M2sNVQaaNUikBuGJjf4ngs2Z3PHuyvpFR/B/yYPOBYowHrG9MkDmfrWch78YA3FZRVcO7iDZzd2JrV7XW4Fi6yN0GkMR0rLeeqrLbzx0y4CA4ShnaO5oFdbzu3Z9tgS+u8u3cNHq/Zy79mpTSZQeEODhWq6EtJg02w4fABaRjf4dqO7xjLaJTFaWl7JvvyjZOQepbisgqGdomvsP27VIpCrByRx9YAkNu8v4JNVmRQUl2EPEAJtAQTaBHuA9XtgchRDO3te3wl941m4JYfnvt3K8NRo+ndoOqv17807yt0zVpEaG0ZC6xCe+HwjqXGtGNqp/v9eP249wK1vr6Br2zCm3zTQbb4oJMjGq9enccc7K3n0k/UcOlzKlBEd6x40kL0JxAZJQ6FlLGRvZMmOg/xm1lr2HDrCdYM70LJFIHPW7ePhj9bx+0/WM6RjG4Z0asOz87YysksMd49pegHdE9oNpZqu3T/B/86HSe9D13F1l2/CCorLuODZHxCBOXePqFdC/WQrKa/gqpcXsyPnMJ9P7kSbFhVc8t5+DhaVMPvO4fXKwcxZt4/73l9NSnRL3psyuM5ho6Xlldw3czVfrN1HVMsgrhvcgeuGdKh5rsOMa6wlbu5cRsUbF7M/O4thhx4jKSqUp67ozeCObQCry2lDZgFfrt/HnHX72XngMO0jgvn87hHHN+tqIjzthmqaHaBKgbV3uNh80hV1qgsPtvPsxL7szT16bO7Iqe6JzzayJiOfp6/sQ4fvH6TVB5N49fo0KioNU95czuESD7faxfpwnrZgG7e/s5Ke7cN555ZBHs0vCAoM4IVJ/Zh56xDOTGrNs/O3MuzJb/ndx+vYkVNU/TnZGymP7sYPW3OYlRFB1OEdTB6SyFf3jjgWKMBaPblXfAQPndeNbx8Yxdf3jeTjO4Y1uUDhDe2GUk1XUCjE9TwtggVYm0jdNSaVZ+dvZXTXWO9H+pxEs1Zk8M7Pe7h1VEfGpbaEj36EyjJSggp4/ldnMvl/S3nwgzW8eM2ZdSa8S8sr+d3H65i1IoOL+7TnqSt6ezV5UUQYmBLFwJQotmUX8dqPO5m1IoP3lu5hQIcoKowh70gpxUeK+KF8J89n9ePZ1Uv5dXgSIVLK48NbQlDNH5UicuKOjs2UtixU05YwwNoIqbKOvb2bibvGdObMpEh+//E6MnJPzWXYN2Tm8/uP1zGkYxseOrcr7PgOKh3zCPYsZlSXGB45vztfrt9f577puYdLufa1n5m1IoN7xqby7MS+DZrl3jm2FX+77AwW/XYMd53VmZLyCloEBtCtbTiTOh4lQAy9+g3mn1f24Z5fTbAuauBM7uZCg4Vq2hLSoLTQ2j/8NBBoC+CZq/thDNz3/uoa9zL3J2MMP207wMIt2WzMLOBAUQmVjmFe+UfK+PXbK2kdGsRzk/pZQ323fQNBYWAPhT1LALhlRAqX9ovnn9/8wpx1+yguq6Bq/nRHThGXvriI1XvyeObqvtx3ThfEGJjzG2sxyQaICWvB/ed25dM7h/PulMFMu+ZM7uxpBbRzRo/h8v4JBLfvCYg1IkppN5Rq4rqeD1GdYOYNcMNn0L7577+d1CaUJyb05P6Zaxj9j4XcODSZqwYkEn4Skt6VlYY/fraB6Yt3n3A8MECICbOSxgeKSpgxdYj12hjYOs/a1bCkAPYsBqyum79ddgbbc4q4/Z2VjmPWGl4hdhvBdhu5R0oJttt4d8og0pIdG25lrYOl/4HSw3DJNN++uawNYGsBUY7JbUEtoXWytiwcNFiopi2kNVz/qTUq6u3L4MY5ENutsWvld5edmUBYsJ1Xf9jBn7/YxL+/+YUr0xK5cWgyydEt/fLM0vJKHvxgDbPXZHLz8BTO79WW7MISsguKyS4sIaughIOHS/h9/+7Hh/fmbIaCDBj1EBTsg++fguICCA4n2G5j+uSBfL42k6KSCo6WlnO0rIKjZRUcKa3AJsJdY1JJauMyamrXj9bv7fOtQOSjCX6ANWw2puuJG3zF9dRg4aDBQjV9kYlWwHh9HLx1CUz+8vi3w2bsnB5xnNMjjvV783l90U7e+Xk30xfvYmy3WPoltcZuE4JsAQQF2qy/AwOICw+mT0Kk14sUHikt59dvr+S7X3L47bhu3Daqo2czsbd+Y/3u7Nh10VRCxlLofDYArVsGcd2QZM8r4gwWhfusD/G4nl69j1plb4KUkScei+0OW76EsmKwB/vuWU2QBgvVPLTpZAWMNy6ANyfATV9BuJ9HC+XuhiUvwrB7PH/W0letdYf6XeuzavSKj+BfV/Xl4XHdePvnPbyzZDfzNmXXWD4wQOjZPpwzO7QmrUMU/Tu0pm1EzR+EeUdKuemNZaxOz+PJy85gojcLLm77xtp/JCIegiOsoc67Fx8LFl6prIDdi6DTWKtlsW2+74LF0VwozIS4Hicej+0BpsIKdO16++ZZTZQGC9V8xPWAaz+C6RdbAWPylz6Z2e3Wnp9hxq/gyAHYvx5umF33/uRbvoI5D1p/V5Q1aGMdd2LDg7n/nC7cd3YqZRWG0opKysorKa2opLS8kpLySnYfPMyK3bms2J3Le0v38L9FuwBoHxFM74RIzkiIoHdCBL3jI4kItbM/v5jrX/+ZXQeO8OI1ZzKuVzvPK1RSaAWGIbdbr1u0sj5wHUlur2Wttxb36321tZDktnkw7O763auq7M3W79gqwcIZjLI3arBo7Aoo5VPxZ8I1M+Gty6wuqRs+hxAf71Wx5n2YfSeEx8PAKbDwb/DDv6x++ZoU7odPb4e4MyC8HXx+HwSHW2sQ+ZiIEBRodTtRZaJy59hWxxYuLKuoZNO+ApbvymVVeh7rMvL4asP+Y2U7tAnlSGkFR0rKeWPyAK+WKAGOD5ntfM7xY0lDYPnrUF4KgV5OYHN2QSUPg/1rYekrVqI7yAc5mmzHRMfY7icej+oItiDNW6DBQjVHHYbCxLfh3YnWt/9rP/JNf3NlJSz4M/zwT0geAVe9aSXYD2y1AkbHUZA40P11H99q7W1+xWsQkQhvXw4fTYUW4ZB6TvVrTgK7LYDeCZH0TjgeTPOPlLFubz5r9+axNj2fQ4dL+b+LenBGQoT3D3AOmU0afPxY0mCr627favf/rWqz60donQIRCdB5LCx+AXYtgi7nel+3qrI3Wf8W4fEnHrfZIbqrDp9F51mo5qrz2XDpy1Yf98dTGz5pr/QwfHC9FSjOvN4KQKFR1mici/5l9cnPuhmO5lW/dvHzsGMhnP+kNdomKBR+NcPq8nj/Oqur5hQREWpneGo0t4/uzMvX9WfmbUPqFyhch8zaXIb0Jg2xfu/x8j078xXJwx33GWrtw75tnvd1cyd7k9WqcJe0j+1e/5ZFRRkcOdSwup0i/BosRGSciGwRkW0i8rCb8zeKSI6IrHb83OJy7ikR2SAim0TkOfHVIvjq9HHGFXDeX61d9b56BOq7aGZBpjU0d9Pn1v3GP3diF0pwBFz+OhTstbqXXJ+zdyXMfwK6j4czbzjxmms/soLMu1fDvrX1q9upyjlktmqrqVWsNS/G27yFM1+RPMJ6bQ+2Asf2+Q2vqzFWMKiar3CK62H927r7IlCbA9vglbPgn91gwV+h7GjD69qI/BYsRMQGTAPOB3oAk0TE3b/G+8aYvo6f/zquHQoMA3oDvYABwCh/1VU1Y0PugCF3WhO5Fj3j/fWZq+HVMXBwO/zqfet+7r63JA6As34HGz6C1e9Yx0qK4MOboVWcFWCqXtcqBq77BFqEwVuXWh8uzYXrkNmqOgyxWhaVXsw+d81XOHUeCwe3Qe6uelcTsPJJR3NrDhaxziS3F3tyr5kB/xlpBZnUc+C7v8O0gdYXjia60rc/WxYDgW3GmB3GmFJgBjDBw2sNEAwEYaXo7ECWX2qpmr9z/gRnXAnz/mD9T+ypTZ9bLYqAQLj5a+hyXu3lh99nffOd8xvrg//L31gfZJe9anVZuROZCNd/Yv39ymiYdROs/9CauNaUbfvG+vCNiK9+LmmI9eF84BfP7+ear3ByDr/d1sDWhbOLqWpy28l5PNuD1X5LiuDjX1s5qvZ94bYfYeI7cOMXENQK3r/Gylc1wS8G/gwW8UC6y+sMx7GqLheRtSIyS0QSAYwxi4EFwD7Hz1xjTLWwLiJTRWS5iCzPycnx/TtQzUNAAEx4EVJGwad31N3PbQwsehbev9b6oLjFw/H8ATa47BWri2r6RVYLY8SDJ34bdic6FSbPgZ6XWCOIZt0ET3W0PlSWvWZ9821KnENma5pLcSxv8ZNn96uar3Bq0xkikmD7t/WvKxxvMdTUsohIsJLfdbUs9q+HV8+CNe/BqN/C9bOPB8vk4XDr9zDuSWuV5BcHw7w/WjmNJsKfwcJdjqFq++szINkY0xuYB0wHEJHOQHcgASvAjBGRKlMrwRjzijEmzRiTFhPT/LYxVD4UGARXvw0x3eH962HdLMjfW71LoLwUZt8F3zxmfXjf+AWEud8j263w9jBhmjXDOGGg9aHhiZiuMOEFePAXmPwVDLrV6vr64n54tg9krPC8Do3NOWS2plFeUR2tXeg8zVtkbTgxX+EkAp3HWM9ryIdu9iarq7BlG/fnRawvDbWNiFrzvtVdWZxvTQ4963dgqzLY1GaHwb+Gu1ZYLd0f/2WN1is9XP+6n0T+DBYZQKLL6wQg07WAMeagMabE8fJVoL/j70uBJcaYImNMEfAlMBilGiI4HK6dZeUKPrwZ/t0Dnu5szcmY90fY8LG1vtSqt2DkQ1bS2h7i/XO6XWh9q/zV+9U/MOoSYLP69M/7C9y9Cn79E7SMgQ9vajpdU9u+sbpcEmv4X1bEGkLr6Ygod/kKp85nW6sOpy+tX13BkdyuoQvKKbaHVc5dviF7kzXvJmEA3LbIGgFWm1axcOlLMP5Zq5X75oQmMWLKn8FiGZAqIikiEgRMBGa7FhAR1+mgFwPOdt4eYJSIBIqIHSu57UV2SakahLWF25fATV/D+U9Dl3FQlA0/PQcf3AjpP8Ol/4Exj1rdV/XVcVTNeQpPiVjdX5f/F/L2HJ/93djKS61lS9wtE35syOzo2ifdJQ2x3lP+3rqf5y5f4ZQy0lpCpL6joiorrZFbNXVBOcX1hOI8q8V4wvUVVtdmUCu48g3ri4in+t9ozdXZt9Za1yw/w9van1R+m5RnjCkXkTuBuYANeN0Ys0FEngCWG2NmA3eLyMVAOXAIuNFx+SxgDLAOq+vqK2PMZ/6qqzrN2EMgaZD141RWbH1zDGl96i1CmDQYRj0MC/8KncZAn4mNV5fifCuXs/N763WnMccT+yInrjJbmw4u8y3OuKLmcpWVVr6i+3j354MjrMl92+bB2Me8fz95u6DsiActC8f5rI0nrgO25EXYuwIuf827QOHUfTxc9xG8NwleO9caTn2Krprs13kWxpg5xpguxphOxnEXVu0AAAqTSURBVJi/OI495ggUGGMeMcb0NMb0McacZYzZ7DheYYy51RjT3RjTwxhzvz/rqRT2YGupkFMtUDiNfNCaiPbFA1YuozHkZ1jfgHf/BBf9G8Y+biV1p4+H/46FjbPhl7lWWXdDZl3FnQH2lnXnLbLWW9/oq+YrXHUea7VyiuoxyOVYcruOAQzOlofr5LyD2+HbP0PXCxq2bEvycGuAQ2U5vH7eiV1q5SXWAIfsTdZ6ZI2Y39DlPpRqCpwjrV4eBh/eAjfN9X5tpYbYtxbe/f/27jzGqvKM4/j3B+5iiihbBBTRVlBxrMSitkbBqlUjLrhrjJqu2mhS22qjbWpjTP/orqlaN1Sk4oJLmyYqWre6sIjFClZcaonKIHWDuAzD0z+ec8uU4JwL3DuXuff3SSZzz8uZe993OHOec973vM97Yp6sTrsTRh2c5eO/A8/fBk/+FqafAeizH5ntqu8mOTelbNyiu/GKilET86T96iMw9sSqmwSsPvkP/EL3+201APoNWb3/qlVw73mwyeZw5C83fF2NIXvm/+mtx8FNR2UCzI/ezbuergbutnoyZw9zug+z3qL/cDj6d/DmXHjk8p773EUP5XwTlKnfK4EC8o5s3Nn5hM/kG3MsYt+vV/e+I/bPJ526mxnd3XhFxdA22Gq79Uv9seRF6L9jZsQtM3jM6mAx67p89PewKzIxZC0MGJljaW2nwM4H5+91wqUZjCbfCMdcndkErj8Ulr5Um89cB76zMOtNxkzKgdEnf5Mn7Z0Pqu/nzb0F7j8/++xPnf7ZV7R9+sIex+VXtUaMByK7XdaWDLBsvOJ/n90nx05eeTh/Zl0eTGhfUD64XTFoTAaJZa/kBM9RE6Ht1Oo/qxr9BuZTUp9l8O45/+aGw/IOb9i42n5+NxwszHqbw67ISW93fzOvQjs7sr+7syPnN6zqzEHYIWOze2Pbnda9m+STD+GBS2DOTXkiPmFKPnpcS8PG5ez4N55ae7CoZryiYtREmH9Hpi6vdh32lZ/CspdhtyOq23/QGFj5cc6NkPKk3tMp64aOzWwCtxybY0Un3txjWYsdLMx6m822ylTnt06Gv12Zk736bJrjAH02zav8D9/KJUwhZx8P2TO/Rh4Iux7W/fyP15+Ee76dj7bu/90cyO6aObZm7dgahu712YPc1YxXVIyakN/nTc1Jf9UEtmWLMshWe2dRWUVv6cLsGuo/vPv962XAyAwYtx4P007O7AR7nVT3j3WwMOuNhuwJF3bTb93xUfavvz0/B6ffng9zb4Znrs71NMadnanWu64k2PExPPwzeOoq2HbHXGmw8ohrvYzYD57+fa7tscfx2VdfGbivZryiYpvBeXfx7LW5uNLwL2UA2eWQvMPq0ye7qN59LX8vS16E1x/Pny17bLZi4G4ZjEeMh31qu8rhOus3KLML3H5apuBfsRT2P6+uH6nopRkQ1zRu3LiYPXt2o6thtvHqXAn//EueUF97DPpunifoyoD0jG/BOy/BuHPgq5dVN+i7oVYsg4d+DAvuzzkcW/TPMYo9joM7zsrXk66s7r06O3L8Y9FDOUmvMmlw64EZcJa+1OXpIuUV+oj9MiNwtTPt33gatv/8hk+4rJWVn2Sg7fgITplWvrTvWkiaExGlgx8OFmatqH0hzPoDzJsGHSsAwTZD88S8y8Ser8/KT/PR1xfugoV/hk+XZ/mx165/F8vy9hz0XjQzr7wHjc4up8Fj8i6hFsuxbgxWdWagXM/VIB0szKzcx+9n2vbl7dmNseW2ja5RXiW//GDOjD7w+z1zh9PCHCzMzKxUtcHCk/LMzKyUg4WZmZVysDAzs1IOFmZmVsrBwszMSjlYmJlZKQcLMzMr5WBhZmalmmZSnqSlwL824C22B96pUXV6E7e7tbjdraWadu8YEaULiDdNsNhQkmZXM4ux2bjdrcXtbi21bLe7oczMrJSDhZmZlXKwWO3aRlegQdzu1uJ2t5aatdtjFmZmVsp3FmZmVsrBwszMSrV8sJB0uKSXJC2SdFGj61NPkm6Q1C7phS5lAyQ9KOnl4vtGsFRa7UgaLukRSQsk/UPS+UV5s7d7C0nPSnq+aPdPi/KRkp4p2n27pM0aXdd6kNRX0nOS/lRst0q7X5c0X9I8SbOLspoc6y0dLCT1Ba4CvgaMAU6RNKaxtaqrm4DD1yi7CJgZEbsCM4vtZrIS+F5EjAbGA+cW/8fN3u5PgAkRsRfQBhwuaTzwc+BXRbvfBc5pYB3r6XxgQZftVmk3wMER0dZlfkVNjvWWDhbAvsCiiHg1Ij4F/ghManCd6iYiHgP+s0bxJGBK8XoKcEyPVqrOIuKtiJhbvP6QPIHsQPO3OyJiebG5afEVwATgzqK86doNIGkYcCRwXbEtWqDd3ajJsd7qwWIH4N9dthcXZa1kcES8BXliBQY1uD51I2knYG/gGVqg3UVXzDygHXgQeAV4LyJWFrs06/H+a+AHwKpieztao92QFwQPSJoj6RtFWU2O9U1qVMHeSmsp87PETUhSP+Au4IKI+CAvNptbRHQCbZL6AzOA0WvbrWdrVV+SjgLaI2KOpIMqxWvZtana3cUBEfGmpEHAg5IW1uqNW/3OYjEwvMv2MODNBtWlUZZIGgpQfG9vcH1qTtKmZKCYGhF3F8VN3+6KiHgP+Cs5ZtNfUuUisRmP9wOAoyW9TnYrTyDvNJq93QBExJvF93byAmFfanSst3qwmAXsWjwpsRlwMnBfg+vU0+4Dzixenwnc28C61FzRX309sCAiftnln5q93QOLOwokbQkcQo7XPAJMLnZrunZHxMURMSwidiL/nh+OiNNo8nYDSNpa0jaV18ChwAvU6Fhv+Rncko4grzz6AjdExOUNrlLdSJoGHESmLV4C/AS4B5gOjADeAE6IiDUHwXstSV8GHgfms7oP+0fkuEUzt3ssOZjZl7wonB4Rl0nambziHgA8B5weEZ80rqb1U3RDXRgRR7VCu4s2zig2NwFui4jLJW1HDY71lg8WZmZWrtW7oczMrAoOFmZmVsrBwszMSjlYmJlZKQcLMzMr5WBhthGQdFAlQ6rZxsjBwszMSjlYmK0DSacX60TMk3RNkaxvuaRfSJoraaakgcW+bZKelvR3STMq6whI2kXSQ8VaE3MljSrevp+kOyUtlDRVrZDAynoNBwuzKkkaDZxEJmtrAzqB04CtgbkR8UXgUXJmPMDNwA8jYiw5g7xSPhW4qlhrYn/graJ8b+ACcm2Vnck8R2YbhVbPOmu2LiYC+wCziov+LcmkbKuA24t9bgXulvQ5oH9EPFqUTwHuKHL37BARMwAi4mOA4v2ejYjFxfY8YCfgifo3y6ycg4VZ9QRMiYiL/69QunSN/brLodNd11LXXEWd+O/TNiLuhjKr3kxgcrFWQGVt4x3Jv6NKRtNTgSci4n3gXUlfKcrPAB6NiA+AxZKOKd5jc0lb9WgrzNaDr1zMqhQRL0q6hFyJrA/QAZwLrAB2lzQHeJ8c14BMB311EQxeBc4qys8ArpF0WfEeJ/RgM8zWi7POmm0gScsjol+j62FWT+6GMjOzUr6zMDOzUr6zMDOzUg4WZmZWysHCzMxKOViYmVkpBwszMyv1X0NGfgl9FIrMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027471565219883"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([model15[i].history['val_acc'][-1] for i in range(0,5)])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1-5:  56.78040244906802\n",
      "stdev 1-5:  0.3100620261988908\n",
      "accuracy 6-10:  64.21872265695588\n",
      "stdev 6-10:  0.7656017948044713\n",
      "accuracy 11-15:  70.27471565219882\n",
      "stdev 11-15:  0.24734815547430275\n",
      "accuracy 16-21:  75.23584493253763\n",
      "stdev 16-21:  0.4721758759849455\n",
      "accuracy 21-25:  79.8058766434307\n",
      "stdev 21-25:  0.39518361048319073\n"
     ]
    }
   ],
   "source": [
    "from statistics import stdev \n",
    "#min1/5\n",
    "print(\"accuracy 1-5: \", sum([model5[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 1-5: \", stdev([model5[i].history['val_acc'][-1] for i in range(0,5)])*100)\n",
    "#min6/10\n",
    "print(\"accuracy 6-10: \", sum([model10[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 6-10: \", stdev([model10[i].history['val_acc'][-1] for i in range(0,5)])*100)\n",
    "#min11/15\n",
    "print(\"accuracy 11-15: \", sum([model15[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 11-15: \", stdev([model15[i].history['val_acc'][-1] for i in range(0,5)])*100)\n",
    "#min16/20\n",
    "print(\"accuracy 16-21: \", sum([model20[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 16-21: \", stdev([model20[i].history['val_acc'][-1] for i in range(0,5)])*100)\n",
    "#min21/25\n",
    "print(\"accuracy 21-25: \", sum([model25[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 21-25: \", stdev([model25[i].history['val_acc'][-1] for i in range(0,5)])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 6-10:  64.21872265695588\n",
      "stdev 6-10:  0.7656017948044713\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy 6-10: \", sum([model10[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 6-10: \", stdev([model10[i].history['val_acc'][-1] for i in range(0,5)])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 21-25:  79.8058766434307\n",
      "stdev 21-25:  0.39518361048319073\n"
     ]
    }
   ],
   "source": [
    "#min21/25\n",
    "print(\"accuracy 21-25: \", sum([model25[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 21-25: \", stdev([model25[i].history['val_acc'][-1] for i in range(0,5)])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 16-21:  75.23584493253763\n",
      "stdev 16-21:  0.4721758759849455\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy 16-21: \", sum([model20[i].history['val_acc'][-1] for i in range(0,5)])/5*100)\n",
    "print(\"stdev 16-21: \", stdev([model20[i].history['val_acc'][-1] for i in range(0,5)])*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
